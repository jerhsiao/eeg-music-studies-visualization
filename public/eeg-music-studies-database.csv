Study Name,Authors,Year,DOI/URL,Dataset,Study Description,Paradigm Type,Stimulus Type,Stimulus Description,Composer,Passage Name,Passage Length,Musical Features Analyzed,Task Description,Number of Participants,Demographics,Musical Training,EEG System Used,Channel Count,Findings,Sampling Rate,Recording Environment,Data Format,Preprocessing,License,EEG Analysis Techniques,Statistical Tests,Event Markers,Publication
Effect of Music and Biofeedback on Alpha Brainwave Rhythms and Attentiveness,Michael Wagner,1975,https://doi.org/10.2307/3345198,NA,This study investigates alpha rhythm production in musicians vs. nonmusicians during passive listening to two musical excerpts (slow and brisk tempo) and silence.,Controlled,Musical Excerpt,"Slow tempo, orchestral",Camille Saint-Saëns,"Saint-Saëns: Symphony No. 3 in C Minor, Op. 78 (2nd Movement)",2 minutes,"Tempo, Pulse, Cortical Activation (Alpha Rhythms), Attentiveness",EEG-monitored passive listening with and without alpha biofeedback; subjects rated attentiveness after each excerpt,60,Undergraduate students from Florida State University; musicians and nonmusicians,Mixed Groups,"Aquarius Electronics ""Alphaphone Brainwave Analyzer""","19 channels, 10–20 system","Musicians produced significantly more alpha than nonmusicians; no significant difference between musical stimuli or feedback condition; attentiveness ratings were higher for music than silence, but alpha rhythm did not correlate with attentiveness reports",Not Reported,Sound-treated room at FSU School of Music,Not Reported,Manual alpha duration timing using EEG-linked timer; no digital preprocessing reported,"Copyright by the Journal of Research in Music Education (MENC), 1975",Manual timing of alpha rhythm duration using EEG-linked digital timer,Repeated-measures ANOVA,Math problems used to block alpha before each aural condition,Journal of Research in Music Education 23(1) 3-13
Effect of Music and Biofeedback on Alpha Brainwave Rhythms and Attentiveness,Michael Wagner,1975,https://doi.org/10.2307/3345198,NA,This study investigates alpha rhythm production in musicians vs. nonmusicians during passive listening to two musical excerpts (slow and brisk tempo) and silence.,Controlled,Musical Excerpt,"Brisk tempo, rhythmic contrast",Jules Massenet,Massenet: Le Cid (“Castillane” movement),3 minutes,"Tempo, Pulse, Cortical Activation (Alpha Rhythms), Attentiveness",EEG-monitored passive listening with and without alpha biofeedback; subjects rated attentiveness after each excerpt,60,Undergraduate students from Florida State University; musicians and nonmusicians,Mixed Groups,"Aquarius Electronics ""Alphaphone Brainwave Analyzer""","19 channels, 10–20 system","Musicians produced significantly more alpha than nonmusicians; no significant difference between musical stimuli or feedback condition; attentiveness ratings were higher for music than silence, but alpha rhythm did not correlate with attentiveness reports",Not Reported,Sound-treated room at FSU School of Music,Not Reported,Manual alpha duration timing using EEG-linked timer; no digital preprocessing reported,"Copyright by the Journal of Research in Music Education (MENC), 1976",Manual timing of alpha rhythm duration using EEG-linked digital timer,Repeated-measures ANOVA,Math problems used to block alpha before each aural condition,Journal of Research in Music Education 23(1) 3-14
Subjective Reactions to Music and Brainwave Rhythms,James Walker,1977,https://doi.org/10.3758/BF03337859,NA,"This study investigates EEG during passive listening to orchestral and rock music; subjects rated emotion, attention, familiarity.",Controlled,Musical Excerpt,"Harp and strings, orchestral",Gustav Mahler ,"Symphony No. 5, 4th Movement (Adagietto)",1.63 minutes,"EEG bandwidths (delta, theta, alpha, beta); attentiveness, emotion, familiarity)","Passive listening with eyes closed; EEG recorded at occipital sites; subjects completed visual analog scales for attentiveness, emotion, and familiarity after each excerpt",24,Undergraduate students (Brandon University),Mixed Groups,Grass Model 79C polygraph,"19 channels, 10–20 system",Alpha and beta power linked to comfort and attention; nonmusicians showed stronger EEG-emotion correlations.,Not Reported,Sound-treated room,Not Reported,Impedance check (<5 kΩ); bipolar montage with Cz reference; manual scoring of 15-second segments,Copyright by Physiological Psychology (1977),Band power (alpha theta delta),"Pearson correlation, t-tests, sign test",Stimulus onset; music vs. silence,Psychobiology 5(4) 345-349
Subjective Reactions to Music and Brainwave Rhythms,James Walker,1977,https://doi.org/10.3758/BF03337859,NA,"This study investigates EEG during passive listening to orchestral and rock music; subjects rated emotion, attention, familiarity.",Controlled,Musical Excerpt,"Electric guitars, drums",Uriah Heap,Gypsy (Instrumental Interlude),1.75 minutes,"EEG bandwidths (delta, theta, alpha, beta); attentiveness, emotion, familiarity)","Passive listening with eyes closed; EEG recorded at occipital sites; subjects completed visual analog scales for attentiveness, emotion, and familiarity after each excerpt",24,Undergraduate students (Brandon University),Mixed Groups,Grass Model 79C polygraph,"19 channels, 10–20 system",EEG-emotion links were weaker; delta power associated with attention; theta linked to unpleasantness.,Not Reported,Sound-treated room,Not Reported,Impedance check (<5 kΩ); bipolar montage with Cz reference; manual scoring of 15-second segments,Copyright by Physiological Psychology (1977),Band power (alpha theta delta),"Pearson correlation, t-tests, sign test",Stimulus onset; music vs. silence,Psychobiology 5(4) 345-350
The EEG: An Adequate Method to Concretize Brain Processes Elicited by Music,"H. Petsche, K. Lindner, P. Rappelsberger, G. Gruber",1988,https://doi.org/10.2307/40285422,NA,"This study investigates whether music processing by the brain can be reflected in ongoing EEG, examining parameters like location, power, frequency, and coherence to identify significant changes in brain electrical activity when listening to various musical stimuli.",Controlled,Musical Excerpt,First movement of Mozart string quartet KV 458,Mozart,String quartet KV 458 (first movement),1 minute,"Brain electrical activity parameters (power, coherence) in different frequency bands (theta, alpha, beta)",Binaural listening to music with eyes closed,75,"Healthy students 52 with musical training, 23 without (40 males, mean age 24.6±6.3 years; 35 females, mean age 22.7±3.7 years)",Mixed Groups,Not specified,19 electrodes (10/20-system),"Listening to Mozart caused strong alpha and theta power reductions, especially in the left hemisphere. Musically trained subjects showed broader alpha blocking and stronger interhemispheric beta 2 coherence, while untrained listeners had more limited effects. In groups split by sex, females showed more extensive interhemispheric coherence (especially beta 1–2) and alpha blocking than males, and trained females drove most of the coherence increases between posterior regions.",256 Hz,Not specified,Digitized analog recordings,Artifact removal by visual inspection; Fourier transformation of 2-sec epochs; averaging of power and cross-power spectra,Copyright by 1996 Elsevier Science B.V.,Spectral analysis; broad band parameter extraction for five frequency bands; Fisher permutation test,Fisher permutation test,Not specified,"Music Perception: An Interdisciplinary Journal, Winter 1988, Vol. 6, No. 2 (Winter, 1988), pp. 133-159"
The EEG: An Adequate Method to Concretize Brain Processes Elicited by Music,"H. Petsche, K. Lindner, P. Rappelsberger, G. Gruber",1988,https://doi.org/10.2307/40285422,NA,"This study investigates whether music processing by the brain can be reflected in ongoing EEG, examining parameters like location, power, frequency, and coherence to identify significant changes in brain electrical activity when listening to various musical stimuli.",Controlled,Spoken Text,Recital of the fate of the sons of J.S. Bach taken from Geiringer's biography,NA,Bach biography excerpt,1 minute,"Brain electrical activity parameters (power, coherence) in different frequency bands (theta, alpha, beta)",Binaural listening with eyes closed,39,"17 females, 22 males",Mixed Groups,Not specified,19 electrodes (10/20-system),"Listening to spoken text caused localized alpha and theta power decreases in the left midtemporal area and beta 1 power increases in the right frontal region. Unlike music, it reduced interhemispheric coherence in posterior areas. Females showed stronger alpha reduction than males.",256 Hz,Not specified,Digitized analog recordings,Artifact removal by visual inspection; Fourier transformation of 2-sec epochs; averaging of power and cross-power spectra,Copyright by 1996 Elsevier Science B.V.,Spectral analysis; broad band parameter extraction for five frequency bands; Fisher permutation test,Fisher permutation test,Not specified,"Music Perception: An Interdisciplinary Journal, Winter 1988, Vol. 6, No. 2 (Winter, 1988), pp. 133-159"
The EEG: An Adequate Method to Concretize Brain Processes Elicited by Music,"H. Petsche, K. Lindner, P. Rappelsberger, G. Gruber",1988,https://doi.org/10.2307/40285422,NA,"This study investigates whether music processing by the brain can be reflected in ongoing EEG, examining parameters like location, power, frequency, and coherence to identify significant changes in brain electrical activity when listening to various musical stimuli.",Controlled,Percussion,"African Jungle Drums, from a record (Primitive Percussion—African Jungle Drums, POP Series R 6001)",Not specified,African Jungle Drums,1 minute,"Brain electrical activity parameters (power, coherence) in different frequency bands (theta, alpha, beta)",Binaural listening with eyes closed,8,"6 males, 2 females",Mixed Groups,Not specified,19 electrodes (10/20-system),Drumming caused alpha power decrease in left midtemporal and central regions and increased theta coherence locally and interhemispherically. Strong motor responses (tapping) likely confounded some EEG changes. No group comparisons were made due to the small sample size.,256 Hz,Not specified,Digitized analog recordings,Artifact removal by visual inspection; Fourier transformation of 2-sec epochs; averaging of power and cross-power spectra,Copyright by 1996 Elsevier Science B.V.,Spectral analysis; broad band parameter extraction for five frequency bands; Fisher permutation test,Fisher permutation test,Not specified,"Music Perception: An Interdisciplinary Journal, Winter 1988, Vol. 6, No. 2 (Winter, 1988), pp. 133-159"
The EEG: An Adequate Method to Concretize Brain Processes Elicited by Music,"H. Petsche, K. Lindner, P. Rappelsberger, G. Gruber",1988,https://doi.org/10.2307/40285422,NA,"This study investigates whether music processing by the brain can be reflected in ongoing EEG, examining parameters like location, power, frequency, and coherence to identify significant changes in brain electrical activity when listening to various musical stimuli.",Controlled,Humming,Voiceless humming of a children's song of participant's choice,Participant's choice,Children's song (participant's choice),1 minute,"Brain electrical activity parameters (power, coherence) in different frequency bands (theta, alpha, beta)",Humming as voicelessly as possible,11,"8 males, 3 females",Mixed Groups,Not specified,19 electrodes (10/20-system),"Humming reduced alpha power in bilateral temporal regions and theta power along the midline, with a large beta 3 power increase linked to motor control. Local beta 3 coherence rose in left hemisphere areas. Interhemispheric coupling increased between frontobasal and parietal regions.",256 Hz,Not specified,Digitized analog recordings,Artifact removal by visual inspection; Fourier transformation of 2-sec epochs; averaging of power and cross-power spectra,Copyright by 1996 Elsevier Science B.V.,Spectral analysis; broad band parameter extraction for five frequency bands; Fisher permutation test,Fisher permutation test,Not specified,"Music Perception: An Interdisciplinary Journal, Winter 1988, Vol. 6, No. 2 (Winter, 1988), pp. 133-159"
The EEG: An Adequate Method to Concretize Brain Processes Elicited by Music,"H. Petsche, K. Lindner, P. Rappelsberger, G. Gruber",1988,https://doi.org/10.2307/40285422,NA,"This study investigates whether music processing by the brain can be reflected in ongoing EEG, examining parameters like location, power, frequency, and coherence to identify significant changes in brain electrical activity when listening to various musical stimuli.",Controlled,Musical Excerpt,German children's song 'Fuchs du hast die Gans gestohlen' played as a single melody on piano,Traditional German children's song,Fuchs du hast die Gans gestohlen,1 minute,"Brain electrical activity parameters (power, coherence) in different frequency bands (theta, alpha, beta)",Binaural listening with eyes closed,19,"9 males, 10 females (music students)",Moderate Training (5-10 years),Not specified,19 electrodes (10/20-system),"Listening to the children's melody caused alpha power reduction mainly in the left temporal and frontal areas, with more extensive local and interhemispheric coherence changes than during Mozart. Repeated presentations showed decreasing EEG changes, suggesting habituation.",256 Hz,Not specified,Digitized analog recordings,Artifact removal by visual inspection; Fourier transformation of 2-sec epochs; averaging of power and cross-power spectra,Copyright by 1996 Elsevier Science B.V.,Spectral analysis; broad band parameter extraction for five frequency bands; Fisher permutation test,Fisher permutation test,Not specified,"Music Perception: An Interdisciplinary Journal, Winter 1988, Vol. 6, No. 2 (Winter, 1988), pp. 133-159"
EEG in Music Psychological Studies,"Helmuth Petsche, K. Lindner, P. Rappelsberger, G. Gruber",1993,https://doi.org/10.1007/978-3-642-79327-1_21,NA,EEG coherence and power were measured while listening to short synthesized tones.,Controlled,Synthesized Music/Tone,Synthesized piano timbre (Yamaha TX7),NA,NA,~30 seconds,"Melodic structure, harmonic context",Passive listening during interictal period; EEG recorded via depth and surface electrodes,2,"Adult males, 31 & 35 years, European",No Formal Training,Depth electrodes + surface EEG (Hess system),"19 channels, 10–20 system","Coherence increased across hemispheres in task-specific patterns, especially in beta bands; music showed unique lateralization vs. verbal tasks.",256 Hz,Hospital neurology lab,Digital EEG (.edf format equivalent),Artifact rejection; visual inspection; FFT windowing (256 samples),"Copyright by Springer, 1988","Coherence analysis, Spectral participation vectors, Band power (delta, theta, alpha, beta)","Coherence computation, frequency quotients",Stimulus onset; synthesized tone presentation,Music Perception 6(1): 79–98
EEG in Music Psychological Studies,"Helmuth Petsche, K. Lindner, P. Rappelsberger, G. Gruber",1993,https://doi.org/10.1007/978-3-642-79327-1_21,NA,EEG coherence and power were measured while listening to short synthesized tones.,Controlled,Synthesized Music/Tone,Pure sine tone,NA,NA,~30 seconds,"Melodic structure, harmonic context",Passive listening during interictal period; EEG recorded via depth and surface electrodes,2,"Adult males, 31 & 35 years, European",No Formal Training,Depth electrodes + surface EEG (Hess system),"19 channels, 10–20 system",Sine tones showed less coherence increase than musical timbres; weaker hemispheric lateralization.,256 Hz,Hospital neurology lab,Digital EEG (.edf format equivalent),Artifact rejection; visual inspection; FFT windowing (256 samples),"Copyright by Springer, 1989","Coherence analysis, Spectral participation vectors, Band power (delta, theta, alpha, beta)","Coherence computation, frequency quotients",Stimulus onset; synthesized tone presentation,Music Perception 6(1): 79–99
EEG in Music Psychological Studies,"Helmuth Petsche, K. Lindner, P. Rappelsberger, G. Gruber",1993,https://doi.org/10.1007/978-3-642-79327-1_21,NA,EEG coherence and power were measured while listening to short synthesized tones.,Controlled,Synthesized Music/Tone,Synthesized cello timbre,NA,NA,~30 seconds,"Melodic structure, harmonic context",Passive listening during interictal period; EEG recorded via depth and surface electrodes,2,"Adult males, 31 & 35 years, European",No Formal Training,Depth electrodes + surface EEG (Hess system),"19 channels, 10–20 system","Coherence patterns differed from piano and sine, with midline beta-band engagement.",256 Hz,Hospital neurology lab,Digital EEG (.edf format equivalent),Artifact rejection; visual inspection; FFT windowing (256 samples),"Copyright by Springer, 1990","Coherence analysis, Spectral participation vectors, Band power (delta, theta, alpha, beta)","Coherence computation, frequency quotients",Stimulus onset; synthesized tone presentation,Music Perception 6(1): 79–100
EEG in Music Psychological Studies,"Helmuth Petsche, K. Lindner, P. Rappelsberger, G. Gruber",1993,https://doi.org/10.1007/978-3-642-79327-1_21,NA,EEG coherence and power were measured while listening to short synthesized tones.,Controlled,Synthesized Music/Tone,Organ-like synthesized tone,NA,NA,~30 seconds,"Melodic structure, harmonic context",Passive listening during interictal period; EEG recorded via depth and surface electrodes,2,"Adult males, 31 & 35 years, European",No Formal Training,Depth electrodes + surface EEG (Hess system),"19 channels, 10–20 system",Elicited broader coherence increases than sine or cello tones; varied across frequency bands.,256 Hz,Hospital neurology lab,Digital EEG (.edf format equivalent),Artifact rejection; visual inspection; FFT windowing (256 samples),"Copyright by Springer, 1991","Coherence analysis, Spectral participation vectors, Band power (delta, theta, alpha, beta)","Coherence computation, frequency quotients",Stimulus onset; synthesized tone presentation,Music Perception 6(1): 79–101
EEG Coherence and Musical Thinking,"Helmuth Petsche, Gerhard Doppelmayr, Peter Rappelsberger, Irenäus Simmerl, Barbara Maresch",1993,https://doi.org/10.2307/40285613,NA,EEG coherence was analyzed in multiple frequency bands while participants passively listened to different solo piano and jazz pieces. This study examines hemispheric and interhemispheric connectivity patterns across different musical styles.,Controlled,Complete Musical Piece,"Piano solo, Mozart – String Quartet KV 458, 1st movement",W.A. Mozart,"Mozart: String Quartet KV 458, 1st movement",4 minutes,"Coherence, Hemispheric activation",Passive listening with eyes closed; EEG recorded from 19 electrodes; music presented via headphones,25,"Mixed gender, healthy participants (ages 13–68)",Not Reported,Not Reported,"19 channels, 10–20 system","Broad bilateral coherence increases, especially in beta 3; high interhemispheric synchrony.",128 Hz,Sound-treated room,Digital EEG traces,Visual artifact rejection; coherence computed using FFT; statistical threshold p ≤ 0.05,Copyright by University of California Press (1993),Coherence analysis (delta to beta3),Frequency-specific comparisons of coherence change (p ≤ 0.05),Not Reported,Music Perception 11(2):117–134
EEG Coherence and Musical Thinking,"Helmuth Petsche, Gerhard Doppelmayr, Peter Rappelsberger, Irenäus Simmerl, Barbara Maresch",1993,https://doi.org/10.2307/40285613,NA,EEG coherence was analyzed in multiple frequency bands while participants passively listened to different solo piano and jazz pieces. This study examines hemispheric and interhemispheric connectivity patterns across different musical styles.,Controlled,Complete Musical Piece,"Piano solo, J.S. Bach – Prelude and Fugue in A Minor",J.S. Bach,Prelude and Fugue in A Minor (Well-Tempered Clavichord I),5 minutes,"Coherence, Hemispheric activation",Passive listening with eyes closed; EEG recorded from 19 electrodes; music presented via headphones,15 Total,"Mixed gender, healthy participants (ages 13–68)",Not Reported,Not Reported,"19 channels, 10–20 system",Strong left-lateralized coherence in beta bands; more asymmetric than Mozart.,128 Hz,Sound-treated room,Digital EEG traces,Visual artifact rejection; coherence computed using FFT; statistical threshold p ≤ 0.06,Copyright by University of California Press (1993),Coherence analysis (delta to beta3),Frequency-specific comparisons of coherence change (p ≤ 0.05),Not Reported,Music Perception 11(2):117–135
EEG Coherence and Musical Thinking,"Helmuth Petsche, Gerhard Doppelmayr, Peter Rappelsberger, Irenäus Simmerl, Barbara Maresch",1993,https://doi.org/10.2307/40285613,NA,EEG coherence was analyzed in multiple frequency bands while participants passively listened to different solo piano and jazz pieces. This study examines hemispheric and interhemispheric connectivity patterns across different musical styles.,Controlled,Complete Musical Piece,"Piano solo, Beethoven – Sonata in A-flat Major, First Movement",Ludwig van Beethoven,"Sonata in A-flat Major, First Movement",5 minutes,"Coherence, Hemispheric activation",Passive listening with eyes closed; EEG recorded from 19 electrodes; music presented via headphones,15 Total,"Mixed gender, healthy participants (ages 13–68)",Not Reported,Not Reported,"19 channels, 10–20 system",Modest coherence changes; less overall engagement than other excerpts.,128 Hz,Sound-treated room,Digital EEG traces,Visual artifact rejection; coherence computed using FFT; statistical threshold p ≤ 0.07,Copyright by University of California Press (1993),Coherence analysis (delta to beta3),Frequency-specific comparisons of coherence change (p ≤ 0.05),Not Reported,Music Perception 11(2):117–136
EEG Coherence and Musical Thinking,"Helmuth Petsche, Gerhard Doppelmayr, Peter Rappelsberger, Irenäus Simmerl, Barbara Maresch",1993,https://doi.org/10.2307/40285613,NA,EEG coherence was analyzed in multiple frequency bands while participants passively listened to different solo piano and jazz pieces. This study examines hemispheric and interhemispheric connectivity patterns across different musical styles.,Controlled,Complete Musical Piece,"Piano solo, Schoenberg – Piano Pieces Op. 33a & b",Arnold Schoenberg,Piano Pieces Op. 33a & b,5 minutes,"Coherence, Hemispheric activation",Passive listening with eyes closed; EEG recorded from 19 electrodes; music presented via headphones,15 Total,"Mixed gender, healthy participants (ages 13–68)",Not Reported,Not Reported,"19 channels, 10–20 system","High left-hemispheric coherence, especially in beta; weaker interhemispheric coupling.",128 Hz,Sound-treated room,Digital EEG traces,Visual artifact rejection; coherence computed using FFT; statistical threshold p ≤ 0.08,Copyright by University of California Press (1993),Coherence analysis (delta to beta3),Frequency-specific comparisons of coherence change (p ≤ 0.05),Not Reported,Music Perception 11(2):117–137
EEG Coherence and Musical Thinking,"Helmuth Petsche, Gerhard Doppelmayr, Peter Rappelsberger, Irenäus Simmerl, Barbara Maresch",1993,https://doi.org/10.2307/40285613,NA,EEG coherence was analyzed in multiple frequency bands while participants passively listened to different solo piano and jazz pieces. This study examines hemispheric and interhemispheric connectivity patterns across different musical styles.,Controlled,Complete Musical Piece,"Jazz piano solo, Amalgame by A. Romano (performed by M. Petrucciani)",A. Romano,Amalgame,5 minutes,"Coherence, Hemispheric activation",Passive listening with eyes closed; EEG recorded from 19 electrodes; music presented via headphones,15 Total,"Mixed gender, healthy participants (ages 13–68)",Not Reported,Not Reported,"19 channels, 10–20 system",Coherence patterns similar to Schoenberg; strong left-lateralized beta activity.,128 Hz,Sound-treated room,Digital EEG traces,Visual artifact rejection; coherence computed using FFT; statistical threshold p ≤ 0.09,Copyright by University of California Press (1993),Coherence analysis (delta to beta3),Frequency-specific comparisons of coherence change (p ≤ 0.05),Not Reported,Music Perception 11(2):117–138
Spectral Analysis of the EEG as a Tool for Evaluating Expectancy Violations of Musical Contexts,"Petr Janata, Helmuth Petsche",1993,https://doi.org/10.2307/40285571,NA,"Musically trained participants listened to cadences resolving to either tonic, minor, or dissonant chords. EEG spectral amplitude and coherence were analyzed for expectancy",Controlled,Synthesized Music/Tone,Cadence + Resolution to Tonic (Best-Fitting),NA,NA,6 seconds,"Harmonic resolution, expectancy fulfillment",Passive listening with judgment of musical resolution quality; EEG recorded from 19 sites; key press or silent response,23,"Music students from Vienna Hochschule für Musik (mean age 24.1 ± 2.7, 13 women, 10 men). All participants had instrumental training (avg. 14.4 ± 4.5 years) and most had theory training (avg. 4.2 ± 3.3 years)",Extensive Training (>10 years),"Nihon Kohden EEG system, digitized with Walter Graphtek “Papierloses EEG”","19 channels, 10–20 system",Right frontal beta coherence increased; minimal deviation from priming cadence in spectral activity; served as baseline for fulfillment.,128 Hz,Sound-treated recording chamber,Digital EEG traces,Artifact rejection via eye-blink monitoring; visual inspection; 2-sec FFT windowing,Copyright by University of California Press (1993),"Spectral amplitude, local coherence, interhemispheric coherence (delta–beta3)",Repeated-measures ANOVA (within-subject: stimulus x response),Serial port trigger aligned to resolution onset,Music Perception 10(3):281–304
Spectral Analysis of the EEG as a Tool for Evaluating Expectancy Violations of Musical Contexts,"Petr Janata, Helmuth Petsche",1993,https://doi.org/10.2307/40285571,NA,"Musically trained participants listened to cadences resolving to either tonic, minor, or dissonant chords. EEG spectral amplitude and coherence were analyzed for expectancy",Controlled,Synthesized Music/Tone,Cadence + Resolution to Minor (Ambiguous),NA,NA,7 seconds,"Harmonic resolution, expectancy fulfillment",Passive listening with judgment of musical resolution quality; EEG recorded from 19 sites; key press or silent response,23,"Music students from Vienna Hochschule für Musik (mean age 24.1 ± 2.7, 13 women, 10 men). All participants had instrumental training (avg. 14.4 ± 4.5 years) and most had theory training (avg. 4.2 ± 3.3 years)",Extensive Training (>10 years),"Nihon Kohden EEG system, digitized with Walter Graphtek “Papierloses EEG”","19 channels, 10–20 system",Slower reaction times and lower accuracy; EEG showed distinct patterns with increased local coherence at central/parietal sites and decreased frontal coherence—interpreted as ambiguity-related processing.,128 Hz,Sound-treated recording chamber,Digital EEG traces,Artifact rejection via eye-blink monitoring; visual inspection; 2-sec FFT windowing,Copyright by University of California Press (1993),"Spectral amplitude, local coherence, interhemispheric coherence (delta–beta3)",Repeated-measures ANOVA (within-subject: stimulus x response),Serial port trigger aligned to resolution onset,Music Perception 10(3):281–304
Spectral Analysis of the EEG as a Tool for Evaluating Expectancy Violations of Musical Contexts,"Petr Janata, Helmuth Petsche",1993,https://doi.org/10.2307/40285571,NA,"Musically trained participants listened to cadences resolving to either tonic, minor, or dissonant chords. EEG spectral amplitude and coherence were analyzed for expectancy",Controlled,Synthesized Music/Tone,Cadence + Resolution to Dissonant (Contextually Distant),NA,NA,8 seconds,"Harmonic resolution, expectancy fulfillment",Passive listening with judgment of musical resolution quality; EEG recorded from 19 sites; key press or silent response,23,"Music students from Vienna Hochschule für Musik (mean age 24.1 ± 2.7, 13 women, 10 men). All participants had instrumental training (avg. 14.4 ± 4.5 years) and most had theory training (avg. 4.2 ± 3.3 years)",Extensive Training (>10 years),"Nihon Kohden EEG system, digitized with Walter Graphtek “Papierloses EEG”","19 channels, 10–20 system","EEG parameters (especially delta and beta coherence) showed stronger deviation from cadence baseline; right temporal amplitude and coherence increased, indicating strong expectancy violation detection.",128 Hz,Sound-treated recording chamber,Digital EEG traces,Artifact rejection via eye-blink monitoring; visual inspection; 2-sec FFT windowing,Copyright by University of California Press (1993),"Spectral amplitude, local coherence, interhemispheric coherence (delta–beta3)",Repeated-measures ANOVA (within-subject: stimulus x response),Serial port trigger aligned to resolution onset,Music Perception 10(3):281–304
EEG Power Spectrum Changes due to Listening to Pleasant Musics and Their Relation to Relaxation Effects,"Michinori Kabuto, Takayuki Kageyama, Hiroshi Nitta",1993,https://doi.org/10.1265/jjh.48.807,NA,This study examined how listening to pleasant music influenced changes in EEG power spectra and psychosomatic relaxation in healthy young adults,Controlled,Musical Excerpt,Classical violin sonata,Ludwig van Beethoven,Beethoven: Violin Sonata No. 9 (Kreutzer),2 minutes,"Delta, Theta, Alpha, Beta power, Alpha peak frequency, Frontal/Occipital activity",Passive listening in sound-insulated room; pre- and post-questionnaires and FFT analysis,42,"Healthy university students (ages 18–25), mixed gender",Not Reported,Nihon-Koden EEG Video System + FFT Analyzer (AD-3524/25),"8 channels, 10-20 system (Fp1-F3, Fp2-F4, F3-P3, F4-P4, P3-O1, P4-O2)",Beethoven increased alpha activity and showed a left-occipital alpha peak shift associated with self-reported relaxation,Not Reported,Sound-insulated room,"EEG digitized to VHS, then converted to FFT","Hanning window, FFT, 50% overlap, baseline regression",© Japanese Journal of Hygiene 1993,"Power spectrum, Alpha peak frequency","Multiple regression, Principal component analysis, GLM, Pearson correlation, t-tests",Before vs. after music period,Japanese Journal of Hygiene 48:807–818
EEG Power Spectrum Changes due to Listening to Pleasant Musics and Their Relation to Relaxation Effects,"Michinori Kabuto, Takayuki Kageyama, Hiroshi Nitta",1993,https://doi.org/10.1265/jjh.48.807,NA,This study examined how listening to pleasant music influenced changes in EEG power spectra and psychosomatic relaxation in healthy young adults,Controlled,Musical Excerpt,Classical piano waltz,Frederic Chopin,Chopin: Waltz Op. 64 No. 1 (Minute Waltz),2 minutes,"Delta, Theta, Alpha, Beta power, Alpha peak frequency, Frontal/Occipital activity",Passive listening in sound-insulated room; pre- and post-questionnaires and FFT analysis,42,"Healthy university students (ages 18–25), mixed gender",Not Reported,Nihon-Koden EEG Video System + FFT Analyzer (AD-3524/25),"8 channels, 10-20 system (Fp1-F3, Fp2-F4, F3-P3, F4-P4, P3-O1, P4-O2)","Chopin increased overall alpha power; associated with subjective calmness and pleasantness, particularly in left-parietal regions",Not Reported,Sound-insulated room,"EEG digitized to VHS, then converted to FFT","Hanning window, FFT, 50% overlap, baseline regression",© Japanese Journal of Hygiene 1993,"Power spectrum, Alpha peak frequency","Multiple regression, Principal component analysis, GLM, Pearson correlation, t-tests",Before vs. after music period,Japanese Journal of Hygiene 48:807–818
EEG Power Spectrum Changes due to Listening to Pleasant Musics and Their Relation to Relaxation Effects,"Michinori Kabuto, Takayuki Kageyama, Hiroshi Nitta",1993,https://doi.org/10.1265/jjh.48.807,NA,This study examined how listening to pleasant music influenced changes in EEG power spectra and psychosomatic relaxation in healthy young adults,Controlled,Musical Excerpt,Commercially produced “α-wave” music,Sony Corp. composers,NA (α-wave commercial relaxation track),2 minutes,"Delta, Theta, Alpha, Beta power, Alpha peak frequency, Frontal/Occipital activity",Passive listening in sound-insulated room; pre- and post-questionnaires and FFT analysis,42,"Healthy university students (ages 18–25), mixed gender",Not Reported,Nihon-Koden EEG Video System + FFT Analyzer (AD-3524/25),"8 channels, 10-20 system (Fp1-F3, Fp2-F4, F3-P3, F4-P4, P3-O1, P4-O2)",Commercial α music produced the largest frontal alpha increase; strongest correlation with high relaxation and calmness scores,Not Reported,Sound-insulated room,"EEG digitized to VHS, then converted to FFT","Hanning window, FFT, 50% overlap, baseline regression",© Japanese Journal of Hygiene 1993,"Power spectrum, Alpha peak frequency","Multiple regression, Principal component analysis, GLM, Pearson correlation, t-tests",Before vs. after music period,Japanese Journal of Hygiene 48:807–818
An Event-Related Potential (ERP) Study of Musical Expectancy: Comparison of Musicians With Nonmusicians,"Mireille Besson, Frederique Faïta",1995,https://doi.org/10.1037/0096-1523.21.6.1278,NA,This ERP study compared musicians and nonmusicians in their neural responses to harmonic and rhythmic violations in familiar and unfamiliar melodies.,Controlled,Computer-Generated Music,Familiar classical melody fragment with congruous terminal note (37-38 phrases),Multiple classical composers,NA,7–13 seconds,"Harmony (diatonic vs nondiatonic), Rhythm (600 ms delay)",Passive listening; post-phrase familiarity & note-congruity judgment; EEG recorded,30,"15 musicians (≥7 yrs training) & 15 nonmusicians, ages 16–39, right-handed",Mixed Groups,Grass P5 RPS107 amplifier,"7 channels, 10-20 system (Fz, Cz, Pz, L/R anterior temporal, L/R posterior temporal), left-mastoid reference",Congruous terminal notes elicited smaller LPCs than violations; ERP differences were more pronounced in musicians.,250 Hz,Shielded laboratory room,Not Reported,Artifact rejection; ocular/muscle-trial removal; ERP averaging,Copyright © 1995 APA,"Event-related potential averaging (LPC, N400-like); mean amplitude & latency measurements",Repeated-measures ANOVA,Terminal-note onset,Journal of Experimental Psychology: Human Perception and Performance 21(6):1278–1296
An Event-Related Potential (ERP) Study of Musical Expectancy: Comparison of Musicians With Nonmusicians,"Mireille Besson, Frederique Faïta",1995,https://doi.org/10.1037/0096-1523.21.6.1278,NA,This ERP study compared musicians and nonmusicians in their neural responses to harmonic and rhythmic violations in familiar and unfamiliar melodies.,Controlled,Computer-Generated Music,Familiar classical melody fragment with out-of-key (nondiatonic) terminal note (37-38 phrases),Multiple classical composers,NA,7–13 seconds,"Harmony (diatonic vs nondiatonic), Rhythm (600 ms delay)",Passive listening; post-phrase familiarity & note-congruity judgment; EEG recorded,30,"15 musicians (≥7 yrs training) & 15 nonmusicians, ages 16–39, right-handed",Mixed Groups,Grass P5 RPS107 amplifier,"7 channels, 10-20 system (Fz, Cz, Pz, L/R anterior temporal, L/R posterior temporal), left-mastoid reference",Out-of-key terminal notes evoked larger LPCs than in-key notes; musicians showed stronger effects.,250 Hz,Shielded laboratory room,Not Reported,Artifact rejection; ocular/muscle-trial removal; ERP averaging,Copyright © 1995 APA,"Event-related potential averaging (LPC, N400-like); mean amplitude & latency measurements",Repeated-measures ANOVA,Terminal-note onset,Journal of Experimental Psychology: Human Perception and Performance 21(6):1278–1297
An Event-Related Potential (ERP) Study of Musical Expectancy: Comparison of Musicians With Nonmusicians,"Mireille Besson, Frederique Faïta",1995,https://doi.org/10.1037/0096-1523.21.6.1278,NA,This ERP study compared musicians and nonmusicians in their neural responses to harmonic and rhythmic violations in familiar and unfamiliar melodies.,Controlled,Computer-Generated Music,Familiar classical melody fragment with in-key but non-cadential (diatonic) terminal note (37-38 phrases),Multiple classical composers,NA,7–13 seconds,"Harmony (diatonic vs nondiatonic), Rhythm (600 ms delay)",Passive listening; post-phrase familiarity & note-congruity judgment; EEG recorded,30,"15 musicians (≥7 yrs training) & 15 nonmusicians, ages 16–39, right-handed",Mixed Groups,Grass P5 RPS107 amplifier,"7 channels, 10-20 system (Fz, Cz, Pz, L/R anterior temporal, L/R posterior temporal), left-mastoid reference",Diatonic non-cadential endings were harder to distinguish; musicians had more defined ERP differences.,250 Hz,Shielded laboratory room,Not Reported,Artifact rejection; ocular/muscle-trial removal; ERP averaging,Copyright © 1995 APA,"Event-related potential averaging (LPC, N400-like); mean amplitude & latency measurements",Repeated-measures ANOVA,Terminal-note onset,Journal of Experimental Psychology: Human Perception and Performance 21(6):1278–1298
An Event-Related Potential (ERP) Study of Musical Expectancy: Comparison of Musicians With Nonmusicians,"Mireille Besson, Frederique Faïta",1995,https://doi.org/10.1037/0096-1523.21.6.1278,NA,This ERP study compared musicians and nonmusicians in their neural responses to harmonic and rhythmic violations in familiar and unfamiliar melodies.,Controlled,Computer-Generated Music,Familiar classical melody fragment with delayed terminal note (600 ms silence) (37-38 phrases),Multiple classical composers,NA,7–13 seconds,"Harmony (diatonic vs nondiatonic), Rhythm (600 ms delay)",Passive listening; post-phrase familiarity & note-congruity judgment; EEG recorded,30,"15 musicians (≥7 yrs training) & 15 nonmusicians, ages 16–39, right-handed",Mixed Groups,Grass P5 RPS107 amplifier,"7 channels, 10-20 system (Fz, Cz, Pz, L/R anterior temporal, L/R posterior temporal), left-mastoid reference",Delayed endings elicited distinct ERP signatures; timing violation detection was not modulated by training.,250 Hz,Shielded laboratory room,Not Reported,Artifact rejection; ocular/muscle-trial removal; ERP averaging,Copyright © 1995 APA,"Event-related potential averaging (LPC, N400-like); mean amplitude & latency measurements",Repeated-measures ANOVA,Expected terminal-note time,Journal of Experimental Psychology: Human Perception and Performance 21(6):1278–1299
An Event-Related Potential (ERP) Study of Musical Expectancy: Comparison of Musicians With Nonmusicians,"Mireille Besson, Frederique Faïta",1995,https://doi.org/10.1037/0096-1523.21.6.1278,NA,This ERP study compared musicians and nonmusicians in their neural responses to harmonic and rhythmic violations in familiar and unfamiliar melodies.,Controlled,Computer-Generated Music,Unfamiliar melody fragment composed for the experiment with congruous terminal note (37-38 phrases),NA,NA,7–13 seconds,"Harmony (diatonic vs nondiatonic), Rhythm (600 ms delay)",Passive listening; post-phrase familiarity & note-congruity judgment; EEG recorded,30,"15 musicians (≥7 yrs training) & 15 nonmusicians, ages 16–39, right-handed",Mixed Groups,Grass P5 RPS107 amplifier,"7 channels, 10-20 system (Fz, Cz, Pz, L/R anterior temporal, L/R posterior temporal), left-mastoid reference",Unfamiliar congruous melodies evoked late negativity; musicians processed them more efficiently.,250 Hz,Shielded laboratory room,Not Reported,Artifact rejection; ocular/muscle-trial removal; ERP averaging,Copyright © 1995 APA,"Event-related potential averaging (LPC, N400-like); mean amplitude & latency measurements",Repeated-measures ANOVA,Terminal-note onset,Journal of Experimental Psychology: Human Perception and Performance 21(6):1278–1300
An Event-Related Potential (ERP) Study of Musical Expectancy: Comparison of Musicians With Nonmusicians,"Mireille Besson, Frederique Faïta",1995,https://doi.org/10.1037/0096-1523.21.6.1278,NA,This ERP study compared musicians and nonmusicians in their neural responses to harmonic and rhythmic violations in familiar and unfamiliar melodies.,Controlled,Computer-Generated Music,Unfamiliar melody fragment composed for the experiment with out-of-key (nondiatonic) terminal note (37-38 phrases),NA,NA,7–13 seconds,"Harmony (diatonic vs nondiatonic), Rhythm (600 ms delay)",Passive listening; post-phrase familiarity & note-congruity judgment; EEG recorded,30,"15 musicians (≥7 yrs training) & 15 nonmusicians, ages 16–39, right-handed",Mixed Groups,Grass P5 RPS107 amplifier,"7 channels, 10-20 system (Fz, Cz, Pz, L/R anterior temporal, L/R posterior temporal), left-mastoid reference",Unfamiliar out-of-key endings produced strong LPCs in musicians; expertise shaped harmonic processing.,250 Hz,Shielded laboratory room,Not Reported,Artifact rejection; ocular/muscle-trial removal; ERP averaging,Copyright © 1995 APA,"Event-related potential averaging (LPC, N400-like); mean amplitude & latency measurements",Repeated-measures ANOVA,Terminal-note onset,Journal of Experimental Psychology: Human Perception and Performance 21(6):1278–1301
An Event-Related Potential (ERP) Study of Musical Expectancy: Comparison of Musicians With Nonmusicians,"Mireille Besson, Frederique Faïta",1995,https://doi.org/10.1037/0096-1523.21.6.1278,NA,This ERP study compared musicians and nonmusicians in their neural responses to harmonic and rhythmic violations in familiar and unfamiliar melodies.,Controlled,Computer-Generated Music,Unfamiliar melody fragment composed for the experiment with in-key but non-cadential (diatonic) terminal note (37-38 phrases),NA,NA,7–13 seconds,"Harmony (diatonic vs nondiatonic), Rhythm (600 ms delay)",Passive listening; post-phrase familiarity & note-congruity judgment; EEG recorded,30,"15 musicians (≥7 yrs training) & 15 nonmusicians, ages 16–39, right-handed",Mixed Groups,Grass P5 RPS107 amplifier,"7 channels, 10-20 system (Fz, Cz, Pz, L/R anterior temporal, L/R posterior temporal), left-mastoid reference",Diatonic unfamiliar endings showed reduced ERP contrast; musicians responded earlier and more strongly.,250 Hz,Shielded laboratory room,Not Reported,Artifact rejection; ocular/muscle-trial removal; ERP averaging,Copyright © 1995 APA,"Event-related potential averaging (LPC, N400-like); mean amplitude & latency measurements",Repeated-measures ANOVA,Terminal-note onset,Journal of Experimental Psychology: Human Perception and Performance 21(6):1278–1302
An Event-Related Potential (ERP) Study of Musical Expectancy: Comparison of Musicians With Nonmusicians,"Mireille Besson, Frederique Faïta",1995,https://doi.org/10.1037/0096-1523.21.6.1278,NA,This ERP study compared musicians and nonmusicians in their neural responses to harmonic and rhythmic violations in familiar and unfamiliar melodies.,Controlled,Computer-Generated Music,Unfamiliar melody fragment composed for the experiment with delayed terminal note (600 ms silence) (37-38 phrases),NA,NA,7–13 seconds,"Harmony (diatonic vs nondiatonic), Rhythm (600 ms delay)",Passive listening; post-phrase familiarity & note-congruity judgment; EEG recorded,30,"15 musicians (≥7 yrs training) & 15 nonmusicians, ages 16–39, right-handed",Mixed Groups,Grass P5 RPS107 amplifier,"7 channels, 10-20 system (Fz, Cz, Pz, L/R anterior temporal, L/R posterior temporal), left-mastoid reference",Delayed endings in unfamiliar melodies triggered prolonged positivity; effects seen across groups.,250 Hz,Shielded laboratory room,Not Reported,Artifact rejection; ocular/muscle-trial removal; ERP averaging,Copyright © 1995 APA,"Event-related potential averaging (LPC, N400-like); mean amplitude & latency measurements",Repeated-measures ANOVA,Expected terminal-note time,Journal of Experimental Psychology: Human Perception and Performance 21(6):1278–1303
Changes in Alpha Band EEG Activity in the Frontal Area After Stimulation with Music of Different Affective Content,"Tatsuya Iwaki, Mitsuo Hayashi, Tadao Hori",1997,https://doi.org/10.1037/0096-1523.21.6.1278,NA,Measured EEG changes during passive listening to emotionally distinct classical music (stimulating vs. calming),Controlled,Complete Musical Piece,Orchestral excerpts with stimulating or calming affect,Gustav Holst,"The Planets – Mars, Venus",3 minutes 40 seconds,"Alpha-2 amplitude, Frontal coherence, Mood ratings",Eyes-closed passive listening followed by mood questionnaire,10,"University students, 5 male and 5 female, ages 21–28",No Formal Training,"TEAC SR-50 recorder, NEC San-Ei Signal Processor","7 channels, 10-20 system (Fz, Cz, Pz, L/R anterior temporal, L/R posterior temporal), left-mastoid reference",Stimulating music increased frontal alpha-2 coherence and amplitude initially; calm music showed less coherence change,200 Hz,Soundproof and air-conditioned chamber (darkened),Digital EEG traces,"High-pass filter (0.5 Hz), Low-pass filter (30 Hz), FFT, Hanning window, Artifact rejection",© Perceptual and Motor Skills 1997,"Power spectrum (alpha-2), Coherence analysis","Repeated-measures ANOVA, t-tests","Phase onset (rest, music: first, middle, latter)",Perceptual and Motor Skills 84(2):515–526
"Brain Indices of Music Processing: ""Nonmusicians"" are Musical","Koelsch, S., Gunter, T., Friederici, A. D., & Schröger, E. ",2000,https://doi.org/10.1162/089892900562183,NA,EEG was recorded while nonmusicians listened to chord sequences with harmonic violations to assess ERPs related to expectancy.,Controlled,Chords/Melody,Chord sequences consisting of 5-chord cadences; 25% included a Neapolitan chord at the 3rd or 5th position; 10% included deviant instrument sounds,NA,NA,~5 seconds,"Harmonic integration and violation detection (ERAN, N5, P3a, P3b)",Passive listening with covert counting of deviant instrument chords,18,"Adult nonmusicians (ages ~21–29, mixed gender)",No Formal Training,Not Reported,"25 channels, 10-20 system","ERAN and N5 were stronger when violations occurred at the 5th chord position, suggesting stronger expectancy buildup. Chords at the 3rd position still elicited these effects but with smaller amplitude.",250 Hz,Acoustically and electrically shielded room,Digital EEG traces,Bandpass filtering (0.5–40 Hz); artifact rejection,Copyright Massachusetts Institute of Technology Journal of Cognitive Neuroscience,"ERP analysis (ERAN, N5, P3 components)",Repeated-measures ANOVA,"Chord position markers (e.g., 3rd, 5th; Neapolitan occurrence)","Journal of Cognitive Neuroscience 12 (3), 2000"
"Brain Indices of Music Processing: ""Nonmusicians"" are Musical","Koelsch, S., Gunter, T., Friederici, A. D., & Schröger, E. ",2000,https://doi.org/10.1162/089892900562183,NA,EEG was recorded while nonmusicians listened to chord sequences with harmonic violations to assess ERPs related to expectancy.,Controlled,Chords/Melody,"Same 5-chord sequences as Exp. 1, but Neapolitan chords replaced by dissonant tone clusters (nonharmonic violations)",NA,NA,~5 seconds,"Violation magnitude and integration difficulty (ERAN, N5, P3a, P3b)",Passive listening with covert counting of deviant instrument chords,18,"Adult nonmusicians (ages ~21–29, mixed gender)",No Formal Training,Not Reported,"25 channels, 10-20 system","Stronger ERAN and N5 than Neapolitans, especially at the 3rd position, indicating greater violation due to both tonal and harmonic incongruity.",250 Hz,Acoustically and electrically shielded room,Digital EEG traces,Bandpass filtering (0.5–40 Hz); artifact rejection,Copyright Massachusetts Institute of Technology Journal of Cognitive Neuroscience,"ERP analysis (ERAN, N5, P3 components)",Repeated-measures ANOVA,Chord position markers; cluster occurrence,"Journal of Cognitive Neuroscience 12 (3), 2000"
"Brain Indices of Music Processing: ""Nonmusicians"" are Musical","Koelsch, S., Gunter, T., Friederici, A. D., & Schröger, E. ",2000,https://doi.org/10.1162/089892900562183,NA,EEG was recorded while nonmusicians listened to chord sequences with harmonic violations to assess ERPs related to expectancy.,Controlled,Chords/Melody,Chord sequences with Neapolitan chords; participants explicitly instructed to detect harmonic violations,NA,NA,~5 seconds,"Harmonic violation processing modulated by attention (ERAN, P3a, P3b, N5)",Active detection of Neapolitan chords (task-relevant),18,"Adult nonmusicians (ages ~21–29, mixed gender)",No Formal Training,Not Reported,"25 channels, 10-20 system","ERAN remained present and amplitude unchanged, even when task relevance increased. Additional P3 components emerged, especially for detected chords, showing attentional engagement.",250 Hz,Acoustically and electrically shielded room,Digital EEG traces,Bandpass filtering (0.5–40 Hz); artifact rejection,Copyright Massachusetts Institute of Technology Journal of Cognitive Neuroscience,"ERP analysis (ERAN, N5, P3 components)",Repeated-measures ANOVA,Chord position markers; behavioral detection markers,"Journal of Cognitive Neuroscience 12 (3), 2000"
"Brain Indices of Music Processing: ""Nonmusicians"" are Musical","Koelsch, S., Gunter, T., Friederici, A. D., & Schröger, E. ",2000,https://doi.org/10.1162/089892900562183,NA,EEG was recorded while nonmusicians listened to chord sequences with harmonic violations to assess ERPs related to expectancy.,Controlled,Chords/Melody,Chord sequences where the probability of out-of-key chords was varied to study expectancy,NA,NA,~5 seconds,"Effects of probability on harmonic violation processing (ERAN, N5)",Passive listening without explicit task instructions,18,"Adult nonmusicians (ages ~21–29, mixed gender)",No Formal Training,Not Reported,"25 channels, 10-20 system","As violation frequency decreased, ERAN and N5 amplitudes increased, confirming sensitivity to violation probability. This supports ERAN as an implicit marker of musical expectation, even in nonmusicians.",250 Hz,Acoustically and electrically shielded room,Digital EEG traces,Bandpass filtering (0.5–40 Hz); artifact rejection,Copyright Massachusetts Institute of Technology Journal of Cognitive Neuroscience,"ERP analysis (ERAN, N5)",Repeated-measures ANOVA,Probability markers (frequency of deviant chords),"Journal of Cognitive Neuroscience 12 (3), 2000"
Differentiating ERAN and MMN: An ERP Study,"Stefan Koelsch, Thomas C. Gunter, Erich Schröger, Mari Tervaniemi, Daniela Sammler, Angela D. Friederici",2001,https://doi.org/10.1097/00001756-200105250-00019,NA,Investigated whether the ERAN reflects cognitive processing of complex musical syntax compared to MMN.,Controlled,Synthesized Music/Tone,Tone pairs rising or falling in pitch (abstract feature MMN),NA,NA,5 events per sequence (tone pairs),Abstract feature (pitch direction),Play videogame while ignoring sounds,28,"Right-handed adults (ages 19–28), 15 female",Nonmusicians (no formal training),Extended 10–20 EEG system,41 channels,Deviant tone pairs elicited abstract feature MMN at ~160 ms; no difference in amplitude between 3rd and 5th position.,250 Hz,EEG booth with video game distraction,Digital EEG traces,"Bandpass 0.25–25 Hz; artifact rejection for drift, EOG; baseline -50 to 0 ms",Lippincott Williams & Wilkins (2001),ERP (MMN extraction),Repeated-measures ANOVA,Second tone onset of tone pair,NeuroReport 12(7):1385–1389
Differentiating ERAN and MMN: An ERP Study,"Stefan Koelsch, Thomas C. Gunter, Erich Schröger, Mari Tervaniemi, Daniela Sammler, Angela D. Friederici",2001,https://doi.org/10.1097/00001756-200105250-00019,NA,Investigated whether the ERAN reflects cognitive processing of complex musical syntax compared to MMN.,Controlled,Chords/Melody,Five-chord harmonic sequences with occasional Neapolitan chords,NA,NA,5 chords per sequence,Musical syntax (harmonic appropriateness),Play videogame while ignoring sounds,28,"Right-handed adults (ages 19–28), 15 female",Nonmusicians (no formal training),Extended 10–20 EEG system,41 channels,"Neapolitan chords elicited ERAN at ~200 ms; ERAN larger at 5th vs 3rd position, indicating context-dependent musical expectancy processing.",250 Hz,EEG booth with video game distraction,Digital EEG traces,"Bandpass 0.25–25 Hz; artifact rejection for drift, EOG; baseline -50 to 0 ms",Lippincott Williams & Wilkins (2001),ERP (ERAN extraction),Repeated-measures ANOVA,Chord onset (3rd and 5th position),NeuroReport 12(7):1385–1389
Differentiating ERAN and MMN: An ERP Study,"Stefan Koelsch, Thomas C. Gunter, Erich Schröger, Mari Tervaniemi, Daniela Sammler, Angela D. Friederici",2001,https://doi.org/10.1097/00001756-200105250-00019,NA,Investigated whether the ERAN reflects cognitive processing of complex musical syntax compared to MMN.,Controlled,Synthesized Music/Tone,Single 440 Hz standard tones and 496 Hz deviant tones,NA,NA,5 tones per sequence,Pitch deviation,Play videogame while ignoring sounds,28,"Right-handed adults (ages 19–28), 15 female",Nonmusicians (no formal training),Extended 10–20 EEG system,41 channels,Deviant tones elicited frequency MMN at ~100 ms; no difference in MMN amplitude between 3rd and 5th position.,250 Hz,EEG booth with video game distraction,Digital EEG traces,"Bandpass 0.25–25 Hz; artifact rejection for drift, EOG; baseline -50 to 0 ms",Lippincott Williams & Wilkins (2001),ERP (frequency MMN extraction),Repeated-measures ANOVA,Tone onset (3rd and 5th position),NeuroReport 12(7):1385–1389
Brain Electrical Activity Evoked by Mental Formation of Auditory Expectations and Images,Petr Janata,2001,https://doi.org/10.1023/A:1007803102254,NA,ERP topographies were examined in response to internally generated auditory imagery and stimulus omissions using melodic fragments with varying expectancy and imagery tasks.,Controlled,Synthesized Music/Tone,D-major scale melodic fragments with brass timbre,NA,NA,"4 seconds (8 notes, 500 ms each)","Imagery, Expectancy, ERP (N100, P200, P300)",Active listening and imagery with timed lever presses during melody completions,7,"Mixed gender, ages 18–42. ≥10 years musical training (mean = 20.7)",Extensive Training (>10 years),Electrical Geodesics Inc. Geodesic Electrode Net,"128 channels, 10-20 system (extended)","Emitted potentials occurred during imagery of the final three notes, with N100-like topographies resembling auditory-evoked potentials, including P200 and a P300-like centro-parietal positivity.",125 Hz,Sound-treated room,Digital EEG traces,"Artifact rejection, Baseline correction, Bandpass filtering at 50 Hz, ERP averaging","Human Sciences Press, Inc.","ERP averaging, Topographic mapping, Permutation analysis","Repeated-measures ANOVA, Scheffé comparisons",Time-locked to imagined note onsets and omissions,Brain Topography 13(3):169–187
Brain Electrical Activity Evoked by Mental Formation of Auditory Expectations and Images,Petr Janata,2001,https://doi.org/10.1023/A:1007803102254,NA,ERP topographies were examined in response to internally generated auditory imagery and stimulus omissions using melodic fragments with varying expectancy and imagery tasks.,Controlled,Synthesized Music/Tone,D-major scale melodic fragments with brass timbre,NA,NA,"4 seconds (8 notes, 500 ms each)","Imagery, Expectancy, ERP (N100, P200), Omissions, Continuations",Imagery task with delayed probe judgment or cue-validity task with attention control,3,"Ages 32–40, Mixed gender. ≥22 years musical training (mean = 25.3)",Extensive Training (>10 years),Electrical Geodesics Inc. Geodesic Electrode Net,"129 channels, 10-20 system (extended)","ERP topographies differed significantly between imagery and non-imagery conditions; emitted potentials occurred only when subjects imagined notes, showing early activity similar to heard tones, and topographical differences during expectancy violations.",250 Hz,Sound-treated room,Digital EEG traces,"Artifact rejection, Z-score standardization, Spline interpolation","Human Sciences Press, Inc.","ERP averaging, Correlation matrix analysis, D-statistic permutation","Bonferroni-corrected correlation, Permutation test",Time-locked to expected and omitted note onsets,Brain Topography 13(3):169–187
Musicians and the gamma band: a secret affair?,"Joydeep Bhattacharya, Hellmuth Petsche",2001,https://doi.org/10.1097/00001756-200102120-00037,NA,EEG phase synchrony during passive listening to music or text was compared between musicians and non-musicians.,Controlled,Complete Musical Piece,French Suite No. 5 (Gigue) for Harpsichord,Johann Sebastian Bach,"French Suite No. 5, Gigue",90 seconds,"Gamma band (30–50 Hz), Phase synchrony, Hemispheric lateralization",Passive listening to Bach harpsichord piece,20,"Right-handed adult males, 10 musicians (≥5 years training) and 10 nonmusicians, mean age ~25.5","Mixed Groups, Moderate Training (5-10 years)",Not Reported,"19 channels, 10-20 system (Fz, Cz, Pz, etc.)","Music listening induced significantly higher gamma-band phase synchrony in musicians than non-musicians, especially in midline and left-hemispheric regions.",128 Hz,Laboratory recording setting,Not reported,"Baseline drift removal, Bandpass filtering, Hilbert transform, Windowed averaging",Lippincott Williams & Wilkins,"Phase synchrony index via Hilbert transform, Topographic profiling, Normalization","Wilcoxon test, Mann-Whitney rank sum, Entropy-based statistics",Time-locked to continuous music listening,NeuroReport 12(2):371–374
Musicians and the gamma band: a secret affair?,"Joydeep Bhattacharya, Hellmuth Petsche",2001,https://doi.org/10.1097/00001756-200102120-00037,NA,EEG phase synchrony during passive listening to music or text was compared between musicians and non-musicians.,Controlled,Spoken Text,Neutral German short story read aloud by female speaker,H. Weigel,Verständigung gegen die Nachwelt,90 seconds,"Gamma band (30–50 Hz), Phase synchrony, Hemispheric lateralization",Passive listening to neutral spoken story,20,"Right-handed adult males, 10 musicians (≥5 years training) and 10 nonmusicians, mean age ~25.5","Mixed Groups, Moderate Training (5-10 years)",Not Reported,"19 channels, 10-20 system (Fz, Cz, Pz, etc.)",No significant differences between groups were observed during text listening; phase synchrony was generally lower across all participants.,128 Hz,Laboratory recording setting,Not reported,"Baseline drift removal, Bandpass filtering, Hilbert transform, Windowed averaging",Lippincott Williams & Wilkins,"Phase synchrony index via Hilbert transform, Topographic profiling, Normalization","Wilcoxon test, Mann-Whitney rank sum, Entropy-based statistics",Time-locked to continuous text listening,NeuroReport 12(2):371–374
Automatic Encoding of Polyphonic Melodies in Musicians and Nonmusicians,"Takako Fujioka, Laurel J. Trainor, Bernhard Ross, Ryusuke Kakigi, Christo Pantev",2005,https://doi.org/10.1162/089892905774597263,NA,Study examined MMNm responses to deviant notes in polyphonic and monophonic melodic contexts in musicians and nonmusicians.,Controlled,Chords/Melody,Two 5-note melodies (A and B) combined polyphonically using piano samples,NA,NA,1.5 seconds,"MMNm, Pitch, Contour, Interval, Voice (High/Low), Tonality (In-key/Out-of-key)",Passive listening to polyphonic melody pairs (oddball paradigm) with MEG recording,20,"Right-handed adult males, 10 musicians (≥5 years training) and 10 nonmusicians, mean age ~25.5","Mixed Groups, Moderate Training (5-10 years)",Whole-head MEG system (CTF OMEGA),151 channels,"Polyphonic condition elicited stronger MMNm overall; musicians showed larger MMNm than nonmusicians, especially to high-voice deviants; in-key deviants evoked larger MMNm than out-of-key; MMNm was left-lateralized in musicians and right-lateralized in nonmusicians.",312.5 Hz,Magnetically shielded room,Digital MEG signals,"Artifact rejection, Signal-space projection, Baseline correction, Bootstrap resampling",Massachusetts Institute of Technology,"MMNm via signal space projection, Auditory dipole modeling, Bootstrapped confidence intervals","Repeated-measures ANOVA (4-way), Fisher’s PLSD, t-tests",Event-locked to 5th note onset of melodies,Journal of Cognitive Neuroscience 17(10):1578–1592
Automatic Encoding of Polyphonic Melodies in Musicians and Nonmusicians,"Takako Fujioka, Laurel J. Trainor, Bernhard Ross, Ryusuke Kakigi, Christo Pantev",2005,https://doi.org/10.1162/089892905774597263,NA,Study examined MMNm responses to deviant notes in polyphonic and monophonic melodic contexts in musicians and nonmusicians.,Controlled,Chords/Melody,"One 5-note melody (A or B), presented without polyphonic pairing",NA,NA,1.5 seconds,"MMNm, Pitch, Contour, Interval, Tonality (In-key/Out-of-key)",Passive listening to single melodies with occasional deviant final notes,20,"Right-handed adult males, 10 musicians (≥5 years training) and 10 nonmusicians, mean age ~25.5","Mixed Groups, Moderate Training (5-10 years)",Whole-head MEG system (CTF OMEGA),151 channels,Monophonic condition elicited MMNm in both groups but with reduced amplitude compared to polyphonic condition; musicians still had greater MMNm overall; behavioral performance was better for out-of-key deviants and higher in musicians.,312.5 Hz,Magnetically shielded room,Digital MEG signals,"Artifact rejection, Signal-space projection, Baseline correction, Bootstrap resampling",Massachusetts Institute of Technology,"MMNm via signal space projection, Auditory dipole modeling, Bootstrapped confidence intervals","Repeated-measures ANOVA (4-way), Fisher’s PLSD, t-tests",Event-locked to 5th note onset of melodies,Journal of Cognitive Neuroscience 17(10):1578–1592
Discovering EEG Signals Response to Musical Signal Stimuli by Time-frequency analysis and Independent Component Analysis,"Wei-Chih Lin, Hung-Wen Chiu, Chien-Yeh Hsu",2005,https://doi.org/10.1109/IEMBS.2005.1617036,NA,Metal music produced high between-subject agreement; most consistent spectral profiles; lower variation in ICA maps across subjects,Controlled,Musical Excerpt,Heavy metal music with high rhythmic intensity,NA,NA,5 minutes,"Frequency band power (delta, theta, alpha, beta, gamma), ICA spatial patterns, Time-frequency plots",Passive listening with eyes closed; 5 music segments presented through earphones,6,"3 male, 3 female, ages 20–28, college students",Not reported,Stellate Harmonie,"21 channels, 10–20 system, Fp1–O2, A1/A2 linked ears",Frontal channels showed strong consistent power response; metal induced similar EEG patterns across listeners,200 Hz,Sound-controlled lab room using headphones,Digital EEG traces,"FFT, Normalization, Artifact rejection, ICA applied for noise separation",© 2005 IEEE,"Time-frequency analysis, Independent Component Analysis, Spectral normalization",Correlation coefficient analysis (within/between subjects),Segment timing by stimulus category,"EMBC 2005 Proceedings, Shanghai, China"
Discovering EEG Signals Response to Musical Signal Stimuli by Time-frequency analysis and Independent Component Analysis,"Wei-Chih Lin, Hung-Wen Chiu, Chien-Yeh Hsu",2005,https://doi.org/10.1109/IEMBS.2005.1617036,NA,"Sonata music induced elevated alpha-band power (8–12 Hz), especially during middle segments; lower cross-subject similarity compared to metal music",Controlled,Musical Excerpt,"Classical sonata music (e.g., Mozart K. 448)",Wolfgang Amadeus Mozart,"Sonata for Two Pianos in D Major, K.448",5 minutes,"Frequency band power (delta, theta, alpha, beta, gamma), ICA spatial patterns, Time-frequency plots",Passive listening with eyes closed; 5 music segments presented through earphones,6,"3 male, 3 female, ages 20–28, college students",Not reported,Stellate Harmonie,"21 channels, 10–20 system, Fp1–O2, A1/A2 linked ears","Frontal and parietal regions (F3, F4, Pz) showed differential power activation; more subject-specific EEG patterns in response to sonata",200 Hz,Sound-controlled lab room using headphones,Digital EEG traces,"FFT, Normalization, Artifact rejection, ICA applied for noise separation",© 2005 IEEE,"Time-frequency analysis, Independent Component Analysis, Spectral normalization",Correlation coefficient analysis (within/between subjects),Segment timing by stimulus category,"EMBC 2005 Proceedings, Shanghai, China"
Discovering EEG Signals Response to Musical Signal Stimuli by Time-frequency analysis and Independent Component Analysis,"Wei-Chih Lin, Hung-Wen Chiu, Chien-Yeh Hsu",2005,https://doi.org/10.1109/IEMBS.2005.1617036,NA,Favorite songs produced diverse EEG responses; lowest between-subject correlation; activity varied across all frequency bands,Controlled,Musical Excerpt,Favorite song chosen by each subject (varied genre),Varied,NA,5 minutes,"Frequency band power (delta, theta, alpha, beta, gamma), ICA spatial patterns, Time-frequency plots",Passive listening with eyes closed; 5 music segments presented through earphones,6,"3 male, 3 female, ages 20–28, college students",Not reported,Stellate Harmonie,"21 channels, 10–20 system, Fp1–O2, A1/A2 linked ears",Highly individual EEG patterns; responses depended on genre and personal familiarity,200 Hz,Sound-controlled lab room using headphones,Digital EEG traces,"FFT, Normalization, Artifact rejection, ICA applied for noise separation",© 2005 IEEE,"Time-frequency analysis, Independent Component Analysis, Spectral normalization",Correlation coefficient analysis (within/between subjects),Segment timing by stimulus category,"EMBC 2005 Proceedings, Shanghai, China"
Pitch Discrimination Accuracy in Musicians vs Nonmusicians,"Mari Tervaniemi, Viola Just, Stefan Koelsch, Andreas Widmann, Erich Schröger",2005,https://doi.org/10.1007/s00221-004-2044-5,NA,Investigated pitch discrimination abilities in musicians vs nonmusicians using both behavioral testing and EEG event-related potentials in response to pitch deviants.,Controlled,Synthetic tones,"Complex tones (528 Hz standard and deviants at +0.76%, +2.1%, +4.2%) with 4 harmonics",N/A,N/A,300 ms tones; 600 ms SOA,Pitch discrimination; frequency deviance,Oddball paradigm with 3 deviant conditions in passive reading (unattend) and active detection (attend); button press in attend condition,26,"13 musicians (mean age ~27.7), 13 nonmusicians (mean age ~21.9)",Mixed Groups,SynAmps (NeuroScan),10 channels + mastoids + EOG,Musicians had enhanced N2b and P3 amplitudes and better behavioral detection in attend condition; no MMN difference in unattend condition,200 Hz,Electrically and acoustically shielded cabin,Not publicly provided,"Band-pass 1–20 Hz, artifact rejection >100µV, mastoid referencing for MMN, nose reference for others",© Springer-Verlag 2004,"ERP components (MMN, P3a, N2b, P3); amplitude quantification in 40-ms windows","2-way and 3-way ANOVAs, post hoc t-tests, Greenhouse-Geisser correction",Deviant stimulus onset,Experimental Brain Research 161:1–10
The Perception of Musical Phrase Structure: A Cross-Cultural ERP Study,"Yun Nan, Thomas R. Knösche, Angela D. Friederici",2006,https://doi.org/10.1016/j.brainres.2006.03.115,NA,ERP study comparing how German and Chinese musicians perceive phrasing in culturally familiar and unfamiliar melodies.,Controlled,Musical Excerpt,Western biphrasal melodies with phrased and unphrased conditions,NA,NA,3–17 seconds (varied),"Phrase boundary perception, CPS, N1, P2, Cultural familiarity","ERP while categorizing melody as Western, Chinese, or combined",12,"German female musicians, ages 21–37, Formal Training Start Age Mean: 7",Moderate Training (5-10 years),Ag-AgCl cap,"51 channels, 10-20 system","The CPS was elicited across all conditions; early ERP components (N1, P2) were modulated by musical style and cultural background.",250 Hz,Electrically shielded room,Digital EEG traces,"Artifact rejection, Bandpass filtering (0.25–100 Hz), Baseline correction, Manual inspection",Elsevier,"ERP averaging, Running t-tests, Time-windowed component analysis","Repeated-measures ANOVA (4-way), Session × Group ANOVA",Trigger at phrase boundary offset,Brain Research 1094:179–191
The Perception of Musical Phrase Structure: A Cross-Cultural ERP Study,"Yun Nan, Thomas R. Knösche, Angela D. Friederici",2006,https://doi.org/10.1016/j.brainres.2006.03.115,NA,ERP study comparing how German and Chinese musicians perceive phrasing in culturally familiar and unfamiliar melodies.,Controlled,Musical Excerpt,Chinese biphrasal melodies with phrased and unphrased conditions,NA,NA,3–17 seconds (varied),"Phrase boundary perception, CPS, N1, P2, Cultural familiarity","ERP while categorizing melody as Western, Chinese, or combined",10,"Chinese female musicians, ages 21–37, Formal Training Start Age Mean: 8",Moderate Training (5-10 years),Ag-AgCl cap,"51 channels, 10-20 system","The CPS occurred regardless of musical style, but cultural background influenced early ERP responses to phrasing.",250 Hz,Electrically shielded room,Digital EEG traces,"Artifact rejection, Bandpass filtering (0.25–100 Hz), Baseline correction, Manual inspection",Elsevier,"ERP averaging, Running t-tests, Time-windowed component analysis","Repeated-measures ANOVA (4-way), Session × Group ANOVA",Trigger at phrase boundary offset,Brain Research 1094:179–191
Effects of Unexpected Chords and of Performer’s Expression on Brain Responses and Electrodermal Activity,"Stefan Koelsch, Simone Kilches, Nikolaus Steinbeis, Stefanie Schelinski",2008,https://doi.org/10.1371/journal.pone.0002631,NA,The study examined how harmonic expectancy and expressive performance affect brain and physiological responses.,Controlled,Chords/Melody,"Original excerpts with unexpected chords, expressive performance","Ludwig van Beethoven, Franz Schubert, W.A. Mozart, Joseph Haydn",NA,8–16 seconds,"Music-syntactic expectancy, ERAN, N5, SCR, Emotional arousal",Passive listening with timbre-deviant detection (button press),20,"Right-handed nonmusicians, ages 19–29, 10 female",No Formal Training,Not Reported,"32 channels, 10-20 system + SCR + ECG",ERAN present; no effect of expression. N5 larger in expressive. SCRs elevated for unexpected chords and expressive performance.,500 Hz,Soundproofed room with fixation cross,Digital EEG and physiological traces,"Artifact rejection, Bandpass filtering (0.25–25 Hz), Baseline correction, Manual inspection",Creative Commons Attribution License,"ERP averaging (ERAN, N5), SCR amplitude averaging, ROI-based analysis","Repeated-measures ANOVA, Paired t-tests, Chi-square tests",Time-locked to final chord onset in each excerpt,PLoS ONE 3(7): e2631
Effects of Unexpected Chords and of Performer’s Expression on Brain Responses and Electrodermal Activity,"Stefan Koelsch, Simone Kilches, Nikolaus Steinbeis, Stefanie Schelinski",2008,https://doi.org/10.1371/journal.pone.0002631,NA,The study examined how harmonic expectancy and expressive performance affect brain and physiological responses.,Controlled,Chords/Melody,"Original excerpts with unexpected chords, non-expressive performance","Ludwig van Beethoven, Franz Schubert, W.A. Mozart, Joseph Haydn",NA,8–16 seconds,"Music-syntactic expectancy, ERAN, N5, SCR, Emotional arousal",Passive listening with timbre-deviant detection (button press),20,"Right-handed nonmusicians, ages 19–29, 10 female",No Formal Training,Not Reported,"32 channels, 10-20 system + SCR + ECG",ERAN present; no effect of expression. N5 larger in expressive. SCRs elevated for unexpected chords and expressive performance.,500 Hz,Soundproofed room with fixation cross,Digital EEG and physiological traces,"Artifact rejection, Bandpass filtering (0.25–25 Hz), Baseline correction, Manual inspection",Creative Commons Attribution License,"ERP averaging (ERAN, N5), SCR amplitude averaging, ROI-based analysis","Repeated-measures ANOVA, Paired t-tests, Chi-square tests",Time-locked to final chord onset in each excerpt,PLoS ONE 3(7): e2631
Effects of Unexpected Chords and of Performer’s Expression on Brain Responses and Electrodermal Activity,"Stefan Koelsch, Simone Kilches, Nikolaus Steinbeis, Stefanie Schelinski",2008,https://doi.org/10.1371/journal.pone.0002631,NA,The study examined how harmonic expectancy and expressive performance affect brain and physiological responses.,Controlled,Chords/Melody,"Excerpts with expected (tonic) chords, expressive performance","Ludwig van Beethoven, Franz Schubert, W.A. Mozart, Joseph Haydn",NA,8–16 seconds,"Expected cadence, SCR, Emotional valence baseline",Passive listening with timbre-deviant detection (button press),20,"Right-handed nonmusicians, ages 19–29, 10 female",No Formal Training,Not Reported,"32 channels, 10-20 system + SCR + ECG",No ERAN or N5 effect. Used as expected cadence baseline. Lower SCRs overall.,500 Hz,Soundproofed room with fixation cross,Digital EEG and physiological traces,"Artifact rejection, Bandpass filtering (0.25–25 Hz), Baseline correction, Manual inspection",Creative Commons Attribution License,"ERP averaging (baseline), SCR control","Repeated-measures ANOVA, Paired t-tests, Chi-square tests",Time-locked to final chord onset in each excerpt,PLoS ONE 3(7): e2631
Effects of Unexpected Chords and of Performer’s Expression on Brain Responses and Electrodermal Activity,"Stefan Koelsch, Simone Kilches, Nikolaus Steinbeis, Stefanie Schelinski",2008,https://doi.org/10.1371/journal.pone.0002631,NA,The study examined how harmonic expectancy and expressive performance affect brain and physiological responses.,Controlled,Chords/Melody,"Excerpts with expected (tonic) chords, non-expressive performance","Ludwig van Beethoven, Franz Schubert, W.A. Mozart, Joseph Haydn",NA,8–16 seconds,"Expected cadence, SCR, Emotional valence baseline",Passive listening with timbre-deviant detection (button press),20,"Right-handed nonmusicians, ages 19–29, 10 female",No Formal Training,Not Reported,"32 channels, 10-20 system + SCR + ECG",No ERAN or N5 effect. Used as expected cadence baseline. Lower SCRs overall.,500 Hz,Soundproofed room with fixation cross,Digital EEG and physiological traces,"Artifact rejection, Bandpass filtering (0.25–25 Hz), Baseline correction, Manual inspection",Creative Commons Attribution License,"ERP averaging (baseline), SCR control","Repeated-measures ANOVA, Paired t-tests, Chi-square tests",Time-locked to final chord onset in each excerpt,PLoS ONE 3(7): e2631
Effects of Unexpected Chords and of Performer’s Expression on Brain Responses and Electrodermal Activity,"Stefan Koelsch, Simone Kilches, Nikolaus Steinbeis, Stefanie Schelinski",2008,https://doi.org/10.1371/journal.pone.0002631,NA,The study examined how harmonic expectancy and expressive performance affect brain and physiological responses.,Controlled,Chords/Melody,"Excerpts with very unexpected (Neapolitan) chords, expressive performance","Ludwig van Beethoven, Franz Schubert, W.A. Mozart, Joseph Haydn",NA,8–16 seconds,"Harmonic violation, Neapolitan, N5, SCR, Surprise",Passive listening with timbre-deviant detection (button press),20,"Right-handed nonmusicians, ages 19–29, 10 female",No Formal Training,Not Reported,"32 channels, 10-20 system + SCR + ECG",ERAN increased vs. expected; N5 enhanced in expressive. SCRs highest in expressive Neapolitan condition.,500 Hz,Soundproofed room with fixation cross,Digital EEG and physiological traces,"Artifact rejection, Bandpass filtering (0.25–25 Hz), Baseline correction, Manual inspection",Creative Commons Attribution License,"ERP averaging (ERAN, N5), SCR amplitude averaging","Repeated-measures ANOVA, Paired t-tests, Chi-square tests",Time-locked to final chord onset in each excerpt,PLoS ONE 3(7): e2631
Effects of Unexpected Chords and of Performer’s Expression on Brain Responses and Electrodermal Activity,"Stefan Koelsch, Simone Kilches, Nikolaus Steinbeis, Stefanie Schelinski",2008,https://doi.org/10.1371/journal.pone.0002631,NA,The study examined how harmonic expectancy and expressive performance affect brain and physiological responses.,Controlled,Chords/Melody,"Excerpts with very unexpected (Neapolitan) chords, non-expressive performance","Ludwig van Beethoven, Franz Schubert, W.A. Mozart, Joseph Haydn",NA,8–16 seconds,"Harmonic violation, Neapolitan, N5, SCR, Surprise",Passive listening with timbre-deviant detection (button press),20,"Right-handed nonmusicians, ages 19–29, 10 female",No Formal Training,Not Reported,"32 channels, 10-20 system + SCR + ECG",ERAN increased vs. expected; N5 not modulated. SCRs elevated but lower than expressive condition.,500 Hz,Soundproofed room with fixation cross,Digital EEG and physiological traces,"Artifact rejection, Bandpass filtering (0.25–25 Hz), Baseline correction, Manual inspection",Creative Commons Attribution License,"ERP averaging (ERAN, N5), SCR amplitude averaging","Repeated-measures ANOVA, Paired t-tests, Chi-square tests",Time-locked to final chord onset in each excerpt,PLoS ONE 3(7): e2631
Single Trial Classification of EEG and Peripheral Physiological Signals for Recognition of Emotions Induced by Music Videos,"Sander Koelstra, Ashkan Yazdani, Mohammad Soleymani, Christian Mühl, Jong-Seok Lee, Anton Nijholt, Thierry Pun, Touradj Ebrahimi, Ioannis Patras",2010,https://doi.org/10.1007/978-3-642-15314-3_9,NA,This study developed single-trial EEG classification for music video-induced emotion using PSD and CSP features,Controlled,Music Videos,20 two-minute music videos spanning 5 valence-arousal quadrants,Multiple commercial artists,NA,2 minutes,"Valence, Arousal, Like/Dislike, Alpha, Theta, Beta, Gamma, Power Spectrum, CSP features, PSD features","Watched 20 music videos and rated valence, arousal, and like/dislike after each; EEG and peripheral signals recorded",6,"Healthy adults, mixed gender, average ages not reported",Not Reported,Biosemi ActiveTwo,"32 channels, 10–20 system","Average classification rates: Valence 58.8%, Arousal 55.7%, Like/Dislike 49.4%; EEG frequency power correlates with subjective valence/arousal ratings",512 Hz,Laboratory with controlled light and temperature,Digital EEG traces,"Common average referencing, high-pass (0.5 Hz), bandpass (0.5–35 Hz), ICA for artifact removal, downsampling to 100 Hz",Springer-Verlag Lecture Notes in Computer Science,"Power spectrum, Common Spatial Patterns (CSP), Frequency band correlation","Spearman correlation, Linear SVM, PCA, Leave-one-trial-out CV, Fisher’s method",Synchronization marker at trial onset,Lecture Notes in Computer Science 6334: 89–100
EEG-Based Emotion Recognition in Music Listening,"Yuan-Pin Lin, Chi-Hong Wang, Tzyy-Ping Jung, Tien-Lin Wu, Shyh-Kang Jeng, Jeng-Ren Duann, Jyh-Horng Chen",2010,https://doi.org/10.1109/TBME.2010.2048568,NA,"This study used EEG power and asymmetry metrics to classify music-induced emotions (joy, anger, sadness, pleasure) with high accuracy",Controlled,Musical Excerpt,Film soundtrack excerpts categorized by emotion,NA,NA,30 seconds per excerpt (16 total),"Valence, Arousal, Alpha asymmetry, Theta, Beta, Gamma, PSD, DASM12, RASM12, Classification accuracy",Passive listening with eyes closed; subjects labeled emotions on 2D valence-arousal grid after each trial,26,"Healthy adults (mean age 24.4 ± 2.5), 16 males, 10 females",No Formal Training,Neuroscan system,"32 channels, 10-20 system",DASM12 with SVM achieved 82.29% classification accuracy; frontal and parietal features were most informative; top-30 subject-independent features identified,500 Hz,Sound-controlled lab room with closed eyes,EEG traces digitized and FFT applied,"Visual artifact rejection, Bandpass filter (1–100 Hz), Notch filter (60 Hz), STFT, Normalization",© IEEE 2010,"Power spectrum, Differential and rational asymmetry (DASM12, RASM12), SVM, MLP classification","10×10-fold cross-validation, t-tests, ANOVA, F-score feature selection, Confusion matrix",Trial-onset of 30s film music clip,IEEE Transactions on Biomedical Engineering 57(7):1798–1806
Tagging the Neuronal Entrainment to Beat and Meter,"Sylvie Nozaradan, Isabelle Peretz, Marcus Missal, André Mouraux",2011,https://doi.org/10.1523/JNEUROSCI.0411-11.2011,NA,EEG was recorded during beat perception and imagined meter tasks to directly assess neural entrainment.,Controlled,Synthesized Music/Tone,333.3 Hz tone with 2.4 Hz beat embedded via amplitude modulation,NA,NA,33 seconds,"Beat entrainment, Steady-State EP, Frequency tagging",Detect 4 ms interruption in pseudo-periodic beat sequence (control condition),8,"Adults (3 female, 7 right-handed), mean age 30 ± 4, 3 with 15–25 years musical training, 5 amateur/dance experience","Mixed Groups, Extensive Training (>10 years)","Waveguard64 cap, ANT Neuro amplifier","64 channels, 10-10 system 4 EOG",Clear EEG response at 2.4 Hz (beat) across all tasks; no difference in beat amplitude across conditions.,1000 Hz,Electrically shielded EEG booth,Digital EEG traces,"0.1 Hz high-pass, ICA blink removal, DFT, noise subtraction",Society for Neuroscience,"Discrete Fourier Transform, Steady-State EP amplitude extraction, ICA","Repeated-measures ANOVA, Paired t-tests, One-sample t-tests",Time-locked to beat onset (2.4 Hz),Journal of Neuroscience 31(28):10234–10240
Tagging the Neuronal Entrainment to Beat and Meter,"Sylvie Nozaradan, Isabelle Peretz, Marcus Missal, André Mouraux",2011,https://doi.org/10.1523/JNEUROSCI.0411-11.2011,NA,EEG was recorded during beat perception and imagined meter tasks to directly assess neural entrainment.,Controlled,Synthesized Music/Tone,Same 2.4 Hz beat tone with binary (1.2 Hz) meter imagined,NA,NA,33 seconds,"Meter entrainment (binary), Frequency-tagged EEG, Beat processing",Imagine binary meter while listening to 2.4 Hz beat sequence,8,"Adults (3 female, 7 right-handed), mean age 30 ± 4, 3 with 15–25 years musical training, 5 amateur/dance experience","Mixed Groups, Extensive Training (>10 years)","Waveguard64 cap, ANT Neuro amplifier","64 channels, 10-10 system 4 EOG",1.2 Hz response emerged only during binary meter imagery; not present in control or ternary.,1000 Hz,Electrically shielded EEG booth,Digital EEG traces,"0.1 Hz high-pass, ICA blink removal, DFT, noise subtraction",Society for Neuroscience,"Discrete Fourier Transform, Steady-State EP amplitude extraction, ICA","Repeated-measures ANOVA, Paired t-tests, One-sample t-tests",Time-locked to beat and imagined meter (1.2 Hz),Journal of Neuroscience 31(28):10234–10240
Tagging the Neuronal Entrainment to Beat and Meter,"Sylvie Nozaradan, Isabelle Peretz, Marcus Missal, André Mouraux",2011,https://doi.org/10.1523/JNEUROSCI.0411-11.2011,NA,EEG was recorded during beat perception and imagined meter tasks to directly assess neural entrainment.,Controlled,Synthesized Music/Tone,Same 2.4 Hz beat tone with ternary (0.8 Hz) meter imagined,NA,NA,33 seconds,"Meter entrainment (ternary), Frequency-tagged EEG, Harmonics",Imagine ternary meter while listening to 2.4 Hz beat sequence,8,"Adults (3 female, 7 right-handed), mean age 30 ± 4, 3 with 15–25 years musical training, 5 amateur/dance experience","Mixed Groups, Extensive Training (>10 years)","Waveguard64 cap, ANT Neuro amplifier","64 channels, 10-10 system 4 EOG",0.8 Hz and 1.6 Hz responses emerged only during ternary imagery; no signal at those frequencies in other conditions.,1000 Hz,Electrically shielded EEG booth,Digital EEG traces,"0.1 Hz high-pass, ICA blink removal, DFT, noise subtraction",Society for Neuroscience,"Discrete Fourier Transform, Steady-State EP amplitude extraction, ICA","Repeated-measures ANOVA, Paired t-tests, One-sample t-tests",Time-locked to beat and imagined meter (0.8 and 1.6 Hz),Journal of Neuroscience 31(28):10234–10240
"DEAP: A Dataset for Emotion Analysis using EEG, Physiological and Video Signals","Sander Koelstra, Christian Mühl, Mohammad Soleymani, Jong-Seok Lee, Ashkan Yazdani, Touradj Ebrahimi, Thierry Pun, Anton Nijholt, Ioannis Patras",2012,https://doi.org/10.1109/T-AFFC.2011.15,https://www.eecs.qmul.ac.uk/mmv/datasets/deap/download.html,The DEAP dataset collected EEG and peripheral physiological signals to assess emotional responses to music videos.,Controlled,Music Videos,"Music video clips with varying ""emotion"" tags",Various,NA,60 seconds,"Valence, Arousal, Dominance, Liking, Familiarity",Watched 40 one-minute music videos and rated them on five affective dimensions,32,"Healthy adults (50% female), ages 19–37, mean age 26.9",Mixed Groups,BioSemi ActiveTwo,32 channels + 13 physiological channels,NA,512 Hz,Controlled lab setting with low illumination,Digital EEG and physiological traces,"Downsampling to 128Hz, EOG removal, Bandpass filtering (4–45Hz), Common reference reordering, Segmentation, Baseline removal",Open Data Commons PDDL,"ERP averaging, Band power, Peripheral signal correlations, Affective quadrant analysis","ANOVA, Regression (RVM), SVM classifiers, Correlation analysis","Trial start markers, Ratings onset, Fixation screens",IEEE Transactions on Affective Computing 3(1):18–31
Individual musical tempo preference correlates with EEG beta rhythm,"Bauer, Kreutz, Herrmann",2014,https://doi.org/10.1111/psyp.12375,NA,"This study explored whether an individual’s preferred tempo correlates with EEG features related to timing and motor processing, particularly beta oscillations.",Controlled,Musical Excerpt,"6–12 s nonvocal rock music excerpts in 4/4 meter, no tempo or key changes",Various,Rock Music Excerpts,6–12 seconds,"Tempo (bpm), Preferred Tempo, Motor beta frequency","Participants tapped and rated perceived tempo of music excerpts across multiple days; EEG recorded during separate tasks for alpha, gamma, and beta band analysis",12 (11 analyzed),"Healthy young adults (21–28 yrs); 6F, right-handed",Mixed (musical sophistication assessed via Gold-MSI),BrainAmp (Brain Products),32 channels,"Preferred tempo significantly correlated with individual motor beta peak frequency (r = 0.71 estimated, r = 0.64 accurate); no correlation with IAF or eGBR",500 Hz,Laboratory environment,"EEG raw signal (0.1–250 Hz), auditory tasks delivered via headphones",Artifact rejection; ICA for artifact removal; band-pass filtering (1–40 Hz); FFT; Morlet wavelet transform,© 2014 Society for Psychophysiological Research,Motor Beta (13–25 Hz); Evoked Gamma Band (30–80 Hz); Individual Alpha Frequency (8–12 Hz); FFT; ICA,Correlation analysis; repeated measures ANOVA,Button press (motor); tone onset (auditory); resting (eyes closed),"Psychophysiology, 52 (2015), 600–604"
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,"Excerpt selected for high arousal/high valence, fast tempo, orchestral texture",Hans Zimmer,Batman Begins: Molossus (Track 18),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,High-energy film score with uplifting brass and strings,Thomas Newman,The Rainmaker: End Title (Track 3),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Energetic electronic piece with bright synth textures and rhythmic drive,Leftfield,Shallow Grave OST: Release the Dub (Track 6),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Orchestral piece with melodic sweep and layered harmonic motion,Rachel Portman,Oliver Twist OST: Main Theme (Track 1),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Historical drama score featuring strong choral and instrumental crescendo,David Reilly,"Man of Galilee (CD1, Track 2)",15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Animated score with whimsical orchestration and dynamic pacing,Alan Menken,Beauty and the Beast OST: West Wing (Track 9),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Contemporary orchestral-electronic hybrid score with escalating momentum,Ramin Djawadi,Iron Man OST: Mark I (Track 4),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Orchestral action score with bold rhythmic sections and brassy textures,John Powell,The Italian Job OST: Mash-up (Track 1),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Upbeat and energetic score with a strong sense of urgency and syncopation,Steve Jablonsky,Transformers OST: Arrival to Earth (Track 7),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Comic and lively orchestral cue with rapid dynamic shifts and upbeat strings,John Williams,Harry Potter OST: Aunt Marge's Waltz (Track 3),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,"Epic orchestral cue with swelling brass, full choir, and rhythmic strings",Hans Zimmer,Gladiator OST: The Might of Rome (Track 5),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Melodramatic orchestral piece with strong dynamic contour and harmonic shifts,Dario Marianelli,Pride & Prejudice OST: Dawn (Track 1),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Energetic symphonic track with heroic brass and staccato rhythm,John Debney,Cutthroat Island OST: Main Title (Track 1),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,"Motivational theme with swelling dynamics, full orchestra and optimistic melody",Craig Armstrong,In Time OST: Escape (Track 7),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,"Orchestral cue with high emotional intensity, use of dissonance and large swells",James Horner,A Beautiful Mind OST: A Kaleidoscope of Mathematics (Track 2),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
Neural correlates of emotional responses to music: An EEG study,"Ian Daly, Asad Malik, Faustina Hwang, Etienne Roesch, James Weaver, Alexis Kirke, Duncan Williams, Eduardo Miranda, Slawomir J. Nasuto",2014,https://doi.org/10.1016/j.neulet.2014.05.003,NA,This EEG study examined how emotional responses to musical excerpts relate to brain activity by measuring gamma coherence and frontal asymmetry during passive listening followed by emotion self-ratings.,Controlled,Musical Excerpt,Animated orchestral comedy track with strong syncopation and rapid phrasing,Mark Mothersbaugh,Cloudy With a Chance of Meatballs OST: Monkey Town (Track 11),15 seconds,"Valence, Arousal, Gamma band coherence, Emotion tagging","Passive listening followed by SAM ratings on valence, arousal, tension, and basic emotions",31,"Adults, median age 35 (range 18–66), 18 female, 29 right-handed",Mixed Groups,Brain Products BrainAmp,"19 channels, 10/20 system (Fp1, Fp2, F7, F3, Fz, F4, F8, T3, C3, Cz, C4, T4, T5, P3, Pz, P4, T6, O1, O2)","Higher gamma coherence was associated with higher reported arousal and valence. Left-frontal asymmetry correlated with positive valence ratings. Gamma coherence and asymmetry measures significantly predicted self-reported emotional experience, indicating neural markers of affective response to music.",1000 Hz,"Quiet lab, participants viewed a fixation cross",Digital EEG traces,"Notch filter (50Hz), bandpass 0.1–45 Hz, ICA, average reference, downsampled to 100 Hz",© 2014 Elsevier Ireland Ltd.,"Coherence, Gamma band asymmetry, Laplacian differences","Stepwise regression, Bonferroni-corrected t-tests",Time-locked to excerpt onset,Neuroscience Letters 573:52–57
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Chim Chim Cheree with lyrics (3/4, 212 BPM)","Robert B. Sherman, Richard M. Sherman",Chim Chim Cheree (lyrics),13.3 seconds,"Tempo, Meter, Lyrics, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury, 8 with 1–10 years formal training, 4 played instruments regularly",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Take Me Out to the Ballgame with lyrics (3/4, 189 BPM)","Jack Norworth, Albert Von Tilzer",Take Me Out to the Ballgame (lyrics),7.7 seconds,"Tempo, Meter, Lyrics, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Jingle Bells with lyrics (4/4, 200 BPM)",James Lord Pierpont,Jingle Bells (lyrics),9.7 seconds,"Tempo, Meter, Lyrics, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Mary Had a Little Lamb with lyrics (4/4, 160 BPM)",Traditional,Mary Had a Little Lamb (lyrics),11.6 seconds,"Tempo, Meter, Lyrics, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Chim Chim Cheree instrumental (3/4, 212 BPM)","Robert B. Sherman, Richard M. Sherman",Chim Chim Cheree,13.5 seconds,"Tempo, Meter, Instrumental, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Take Me Out to the Ballgame instrumental (3/4, 189 BPM)","Jack Norworth, Albert Von Tilzer",Take Me Out to the Ballgame,7.7 seconds,"Tempo, Meter, Instrumental, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Jingle Bells instrumental (4/4, 200 BPM)",James Lord Pierpont,Jingle Bells,9.0 seconds,"Tempo, Meter, Instrumental, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Mary Had a Little Lamb instrumental (4/4, 160 BPM)",Traditional,Mary Had a Little Lamb,12.2 seconds,"Tempo, Meter, Instrumental, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Emperor Waltz (3/4, 178 BPM)",Johann Strauss II,Emperor Waltz,8.3 seconds,"Tempo, Meter, Orchestral, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Hedwig’s Theme (Harry Potter, 3/4, 166 BPM)",John Williams,Hedwig's Theme,16.0 seconds,"Tempo, Meter, Film score, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Imperial March (Star Wars Theme, 4/4, 104 BPM)",John Williams,Imperial March,9.2 seconds,"Tempo, Meter, Film score, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
OPENMIIR: A Public Dataset of EEG Recordings During Music Perception and Imagination,"Sebastian Stober, Avital Sternin, Adrian M. Owen, Jessica A. Grahn",2015,https://doi.org/10.6084/m9.figshare.1541151.v1,https://github.com/sstober/openmiir,The OPENMIIR dataset contains EEG responses to perception and imagination of well-known musical fragments.,Controlled,Complete Musical Piece,"Eine Kleine Nachtmusik (4/4, 140 BPM)",Wolfgang Amadeus Mozart,Eine Kleine Nachtmusik,6.9 seconds,"Tempo, Meter, Classical string ensemble, Imagery","Participants either passively listened to music preceded by cue clicks, imagined music with or without cue clicks, or imagined music without cues and rated confidence",10,"Adults (3 male), ages 19–36, normal hearing, no brain injury",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 4 EOG",NA,512 Hz,Soundproof audiometric booth,Digital EEG traces in FIF format,"Visual inspection, ICA, Re-referencing, Bandpass 0.5–30 Hz, Downsampling to 64 Hz",Open Data Commons Public Domain Dedication and License (PDDL),"ERP averaging, PCA, Beat-locked ERP",None reported,Time-locked to cue click onset and stimulus onset or imagination block onset,ISMIR 2015 Proceedings
Event-Related Brain Responses While Listening to Entire Pieces of Music,"H. Poikonen, V. Alluri, E. Brattico, O. Lartillot, M. Tervaniemi, M. Huotilainen",2016,https://doi.org/10.1016/j.neuroscience.2015.10.061,NA,This study used an ERP-based method for analyzing brain responses to continuous music,Naturalistic,Complete Musical Piece,Live-recorded modern tango with dynamic shifts in timbre and loudness,Astor Piazzolla,Adios Nonino,8 minutes (last 30s removed),"Brightness, Spectral flux, Zero-crossing rate, RMS (loudness), N100, P200","Passive listening with eyes open, EEG recorded during entire piece",16,"Right-handed Finnish adults, 10 female, age 20–46, Musical laymen, some with informal training in instruments or dance",Mixed Groups,BioSemi ActiveTwo ,"64 channels, 10/10 system + 5 external electrodes","The study revealed significant ERP components (N100, P200) time-locked to rapid acoustic changes, demonstrating cortical responses to structural features in natural music.",2048 Hz,Sound-attenuated room,Continuous EEG traces (BioSemi BDF),"ICA artifact removal, Downsampling to 256 Hz, Bandpass filtering (1–30 Hz), Baseline correction, Epoch rejection (±100 µV), Visual inspection",Crown Copyright © 2015 Elsevier Ltd.,"ERP averaging (N100, P200), Feature-triggered ERP extraction","Two-way ANOVA, One-sample t-tests, Shapiro–Wilk tests, Pairwise comparisons","Feature-triggered, time-locked to rapid acoustic changes",Neuroscience 312:58–73
Event-Related Brain Responses While Listening to Entire Pieces of Music,"H. Poikonen, V. Alluri, E. Brattico, O. Lartillot, M. Tervaniemi, M. Huotilainen",2016,https://doi.org/10.1016/j.neuroscience.2015.10.061,NA,This study used an ERP-based method for analyzing brain responses to continuous music,Naturalistic,Complete Musical Piece,Looped acoustic lullaby with unclear vocals resembling humming,Kira Kira,Bless,5 minutes 43 seconds,"Brightness, Spectral flux, Zero-crossing rate, RMS (loudness), N100, P200","Passive listening with eyes open, EEG recorded during entire piece",16,"Right-handed Finnish adults, 10 female, age 20–46, Musical laymen, some with informal training in instruments or dance",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 5 external electrodes","The study found consistent ERP responses (N100, P200) to changes in brightness and spectral flux, indicating sensitivity to timbral variation in a minimal acoustic context.",2048 Hz,Sound-attenuated room,Continuous EEG traces (BioSemi BDF),"ICA artifact removal, Downsampling to 256 Hz, Bandpass filtering (1–30 Hz), Baseline correction, Epoch rejection (±100 µV), Visual inspection",Crown Copyright © 2015 Elsevier Ltd.,"ERP averaging (N100, P200), Feature-triggered ERP extraction","Two-way ANOVA, One-sample t-tests, Shapiro–Wilk tests, Pairwise comparisons","Feature-triggered, time-locked to rapid acoustic changes",Neuroscience 312:58–73
Event-Related Brain Responses While Listening to Entire Pieces of Music,"H. Poikonen, V. Alluri, E. Brattico, O. Lartillot, M. Tervaniemi, M. Huotilainen",2016,https://doi.org/10.1016/j.neuroscience.2015.10.061,NA,This study used an ERP-based method for analyzing brain responses to continuous music,Naturalistic,Complete Musical Piece,Deep techno track with regular beat and low harmonic content,Len Faki (remixed by Radio Slave),My Black Sheep Radio Slave,5 minutes 20 seconds,"Brightness, Spectral flux, Zero-crossing rate, RMS (loudness), N100, P200","Passive listening with eyes open, EEG recorded during entire piece",16,"Right-handed Finnish adults, 10 female, age 20–46, Musical laymen, some with informal training in instruments or dance",Mixed Groups,Biosemi ActiveTwo,"64 channels, 10/10 system + 5 external electrodes","The study reported ERP components (N100, P200) in response to rapid acoustic shifts, confirming neural entrainment even in rhythmically repetitive and harmonically sparse stimuli.",2048 Hz,Sound-attenuated room,Continuous EEG traces (BioSemi BDF),"ICA artifact removal, Downsampling to 256 Hz, Bandpass filtering (1–30 Hz), Baseline correction, Epoch rejection (±100 µV), Visual inspection",Crown Copyright © 2015 Elsevier Ltd.,"ERP averaging (N100, P200), Feature-triggered ERP extraction","Two-way ANOVA, One-sample t-tests, Shapiro–Wilk tests, Pairwise comparisons","Feature-triggered, time-locked to rapid acoustic changes",Neuroscience 312:58–73
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"Bonobo – “First Fires” (ASIN B00CJE73J6, 55.97 BPM)",Bonobo,First Fires,4:38 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing, 17 reported musical training (mean 8.4 years)","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"LA Priest – “Oino” (ASIN B00T4NHS2W, 69.44 BPM)",LA Priest,Oino,4:31 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"Daedelus – “Tiptoes” (ASIN B011SAZRLC, 74.26 BPM)",Daedelus,Tiptoes,4:36 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"Croquet Club – “Careless Love” (ASIN B06X9736NJ, 82.42 BPM)",Croquet Club,Careless Love,4:54 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"Thievery Corporation – “Lebanese Blonde” (ASIN B000SF16MI, 91.46 BPM)",Thievery Corporation,Lebanese Blonde,4:49 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"Polo & Pan – “Canopee” (ASIN B01GOL4IB0, 96.15 BPM)",Polo & Pan,Canopee,4:36 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"Kazy Lambist – “Doing Yoga” (ASIN B01JDDVIQ4, 108.70 BPM)",Kazy Lambist,Doing Yoga,4:52 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"Rüfüs du Sol – “Until the Sun Needs to Rise” (ASIN B01APT6JKA, 120 BPM)",Rüfüs du Sol,Until the Sun Needs to Rise,4:52 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"The Knife – “Silent Shout” (ASIN B00IMN40O4, 128.21 BPM)",The Knife,Silent Shout,4:54 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
NMED-T: A Tempo-Focused Dataset of Cortical and Behavioral Responses to Naturalistic Music,"Steven Losorelli, Duc T. Nguyen, Jacek P. Dmochowski, Blair Kaneshiro",2017,https://archives.ismir.net/ismir2017/paper/000198.pdf,https://purl.stanford.edu/jn859kj8079,"The NMED-T dataset provides open-access EEG, tapping, and behavioral response data from 20 participants listening to 10 tempo-varied, beat-driven songs, enabling reproducible research in neuroscience and cognitive MIR.",Naturalistic,Complete Musical Piece,"David Bowie – “The Last Thing You Should Do” (ASIN B018GS2A46, 150 BPM)",David Bowie,The Last Thing You Should Do,4:58 minutes,"Tempo, Beat entrainment, Spectral energy","Participants listened to 10 full-length songs during EEG, then tapped along to 35-second excerpts in a separate behavioral session",20,"Right-handed adults, ages 18–29, 6 female, normal hearing","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system, vertex reference",NA,1000 Hz,Sound-treated lab and quiet room,Digital EEG + tap timing + behavioral ratings,"Downsampling to 125 Hz, High-pass + notch + low-pass filtering, ICA, interpolation, average referencing",CC BY 4.0,"SS-EPs, PCA, Time-frequency analysis","Correlation analysis, Spectral power comparison","Audio-click sync, Tap timestamps from iPad",ISMIR 2017: 339–346
Neural Tracking of the Musical Beat is Enhanced by Low-Frequency Sounds,"Lenc, Keller, Varlet, Nozaradan",2018,https://doi.org/10.1073/pnas.1801421115,NA,This study used EEG and frequency tagging to examine how low vs. high tones influence neural tracking of rhythmic beats and meter.,Controlled,Synthetic Rhythms,"Pure tones (130 Hz or 1236.8 Hz) forming isochronous, unsyncopated, or syncopated rhythms, looped for 60 seconds",N/A,Isochronous Rhythm,60 seconds,"Neural entrainment, frequency tagging, beat and meter tracking",EEG-monitored passive listening with deviant duration detection; tapping task after EEG,14,"Mean age 28.4, 10 female",Moderate Training (5-10 years),Biosemi ActiveTwo,64,Low tones enhanced EEG activity at beat frequency; strongest effects seen in syncopated rhythm.,2048 Hz,Sound-attenuated lab,Digitized EEG,"Filtered, downsampled, artifact rejection, common average referencing",CC BY-NC-ND,"Frequency tagging, z-score standardization, cochlear model comparison","Repeated-measures ANOVA, t-tests, permutation tests","Rhythm onset, tone deviants",PNAS 115(32):8221–8226
Neural Tracking of the Musical Beat is Enhanced by Low-Frequency Sounds,"Lenc, Keller, Varlet, Nozaradan",2018,https://doi.org/10.1073/pnas.1801421115,NA,This study used EEG and frequency tagging to examine how low vs. high tones influence neural tracking of rhythmic beats and meter.,Controlled,Synthetic Rhythms,"Pure tones (130 Hz or 1236.8 Hz) forming isochronous, unsyncopated, or syncopated rhythms, looped for 60 seconds",N/A,Unsyncopated Rhythm,60 seconds,"Neural entrainment, frequency tagging, beat and meter tracking",EEG-monitored passive listening with deviant duration detection; tapping task after EEG,14,"Mean age 28.4, 10 female",Moderate Training (5-10 years),Biosemi ActiveTwo,64,Beat frequency enhancement with low tones; no meter effect.,2048 Hz,Sound-attenuated lab,Digitized EEG,"Filtered, downsampled, artifact rejection, common average referencing",CC BY-NC-ND,"Frequency tagging, z-score standardization, cochlear model comparison","Repeated-measures ANOVA, t-tests, permutation tests","Rhythm onset, tone deviants",PNAS 115(32):8221–8226
Neural Tracking of the Musical Beat is Enhanced by Low-Frequency Sounds,"Lenc, Keller, Varlet, Nozaradan",2018,https://doi.org/10.1073/pnas.1801421115,NA,This study used EEG and frequency tagging to examine how low vs. high tones influence neural tracking of rhythmic beats and meter.,Controlled,Synthetic Rhythms,"Pure tones (130 Hz or 1236.8 Hz) forming isochronous, unsyncopated, or syncopated rhythms, looped for 60 seconds",N/A,Syncopated Rhythm,60 seconds,"Neural entrainment, frequency tagging, beat and meter tracking",EEG-monitored passive listening with deviant duration detection; tapping task after EEG,14,"Mean age 28.4, 10 female",Moderate Training (5-10 years),Biosemi ActiveTwo,64,Low tones boosted EEG responses at both beat and meter frequencies for syncopated rhythms.,2048 Hz,Sound-attenuated lab,Digitized EEG,"Filtered, downsampled, artifact rejection, common average referencing",CC BY-NC-ND,"Frequency tagging, z-score standardization, cochlear model comparison","Repeated-measures ANOVA, t-tests, permutation tests","Rhythm onset, tone deviants",PNAS 115(32):8221–8226
NMED-RP Naturalistic Music EEG Dataset – Rhythm Pilot,"Appaji, Jay, Kaneshiro, Blair",2018,NA,https://purl.stanford.edu/rz763kn3821,Pilot study examined EEG and behavioral responses to brief rhythmic musical excerpts.,Naturalistic,Musical Excerpt,Excerpts of natural music and rhythmic patterns; multiple listens,Various,NA,30 seconds,"Rhythmic complexity, Beat perception, Enjoyment, Temporal attention","Participants listened to 16 different musical excerpts multiple times and rated enjoyment, rhythmic complexity, and ease of finding the beat after each trial",5,"Adults with normal hearing; individual sessions, mixed gender",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system + reference",ERP averaging performed; dataset supports future exploration of rhythmic complexity and enjoyment.,1000 Hz,Controlled EEG lab setting,Digital EEG traces and behavioral ratings in .mat format,"Not explicitly detailed; assumed filtering, epoching, downsampling based on NMED family standards",CC BY 3.0,"RCA, ERP averaging, Descriptive statistics",Not reported (pilot dataset),Trial-aligned EEG blocks with per-trial behavioral ratings,Stanford Digital Repository (2018): https://purl.stanford.edu/rz763kn3821
"Rhesus Monkeys (Macaca mulatta) Sense Isochrony in Rhythm, but Not the Beat: Additional Support for the Gradual Audiomotor Evolution Hypothesis","Henkjan Honing, Fleur Bouwer, Gámez José, Hugo Merchant",2018,https://doi.org/10.3389/fnins.2018.00475,NA,"This study used EEG to examine whether rhesus monkeys can detect isochrony and perceive beats in rhythmic sound sequences, testing their auditory timing abilities in support of the Gradual Audiomotor Evolution Hypothesis.",Controlled,Synthesized Music/Tone,Accented and unaccented percussive sounds in isochronous pattern,NA,NA,~9:45 minutes per block,"MMN, P3a, P1, N1, Isochrony sensitivity, Beat perception",Passive listening to rhythmic sequences with deviant detection,2,"Rhesus monkeys (Macaca mulatta), adult males",Not Applicable,"Grass EEG electrodes (Fz, Cz, Pz, F3, F4) with Tucker-Davis Technologies hardware","5 channels, 10–20 system","Monkeys exhibited larger mismatch negativity (MMN) in the isochronous condition, indicating sensitivity to isochrony. However, no interaction between metrical position and isochrony was observed—supporting the conclusion that while monkeys detect temporal regularity, they do not perceive beat structure.",498.25 Hz,Acoustically treated cage with loudspeakers 1.1m away,Digital EEG traces,"Artifact rejection, 5–75 Hz bandpass filter, no baseline correction","© 2018 Honing et al., Frontiers Media S.A.","ERP averaging (MMN, P3a, P1, N1)","ANOVA (with factors Isochrony, Position, and Type)",Time-locked to deviant onset in rhythmic streams,Frontiers in Neuroscience 12:475
"Rhesus Monkeys (Macaca mulatta) Sense Isochrony in Rhythm, but Not the Beat: Additional Support for the Gradual Audiomotor Evolution Hypothesis","Henkjan Honing, Fleur Bouwer, Gámez José, Hugo Merchant",2018,https://doi.org/10.3389/fnins.2018.00475,NA,"This study used EEG to examine whether rhesus monkeys can detect isochrony and perceive beats in rhythmic sound sequences, testing their auditory timing abilities in support of the Gradual Audiomotor Evolution Hypothesis.",Controlled,Synthesized Music/Tone,Accented and unaccented percussive sounds in jittered pattern,NA,NA,~9:45 minutes per block,"MMN, P3a, P1, N1, Isochrony sensitivity, Beat perception",Passive listening to rhythmic sequences with deviant detection,2,"Rhesus monkeys (Macaca mulatta), adult males",Not Applicable,"Grass EEG electrodes (Fz, Cz, Pz, F3, F4) with Tucker-Davis Technologies hardware","5 channels, 10–20 system","Monkeys still showed MMN responses to deviant stimuli but of lower amplitude compared to the isochronous condition. The absence of interaction with metrical structure confirms lack of beat perception, reinforcing the Gradual Audiomotor Evolution hypothesis that beat-based timing evolved gradually and is largely absent in monkeys.",498.25 Hz,Acoustically treated cage with loudspeakers 1.1m away,Digital EEG traces,"Artifact rejection, 5–75 Hz bandpass filter, no baseline correction","© 2018 Honing et al., Frontiers Media S.A.","ERP averaging (MMN, P3a, P1, N1)","ANOVA (with factors Isochrony, Position, and Type)",Time-locked to deviant onset in rhythmic streams,Frontiers in Neuroscience 12:475
NMED-H 2.0: Naturalistic Music EEG Dataset—Hindi,"Kaneshiro, Blair, Nguyen, Duc T., Dmochowski, Jacek P., Norcia, Anthony M., and Berger, Jonathan",2019,https://purl.stanford.edu/sd922db3535,https://purl.stanford.edu/sd922db3535,This study examined how intact and manipulated temporal structure of Hindi pop music affects inter-subject EEG correlation.,Naturalistic,Complete Musical Piece,Four Various Hindi pop songs – intact temporal structure,Various,NA,~4.5 minutes,"Temporal structure, Beat tracking, Inter-subject correlation","Each participant heard one of four songs under four temporal conditions (intact, shuffled, reversed, scrambled); listened twice per stimulus and rated Pleasantness, Musicality, Order, and Interest",12,"Adults with normal hearing; 50% female, right-handed",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system + reference",ISC and variance explained were highest for intact condition; behavioral ratings aligned with EEG responses.,"1000 Hz (raw), 125 Hz (clean)",Sound-treated EEG lab,"Digital EEG (raw, clean, RCA), behavioral ratings","Filtering, downsampling, artifact rejection, re-referencing, spatial filtering (RCA)",CC BY 4.0,"RCA, Inter-subject correlation, Time-domain analysis","ISC, Variance explained, Behavioral-EEG correlation",Trial-aligned per condition and stimulus,ISMIR 2019 Late-Breaking/Demo
NMED-H 2.0: Naturalistic Music EEG Dataset—Hindi,"Kaneshiro, Blair, Nguyen, Duc T., Dmochowski, Jacek P., Norcia, Anthony M., and Berger, Jonathan",2019,https://purl.stanford.edu/sd922db3535,https://purl.stanford.edu/sd922db3535,This study examined how intact and manipulated temporal structure of Hindi pop music affects inter-subject EEG correlation.,Naturalistic,Complete Musical Piece,Four Various Hindi pop songs  – measure-shuffled,Various,NA,~4.5 minutes,"Temporal disruption, Beat segmentation, Neural response variability","Each participant heard one of four songs under four temporal conditions (intact, shuffled, reversed, scrambled); listened twice per stimulus and rated Pleasantness, Musicality, Order, and Interest",12,"Adults with normal hearing; 50% female, right-handed",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system + reference","ISC and behavioral ratings decreased in measure-shuffled condition, reflecting disruption in temporal structure.","1000 Hz (raw), 125 Hz (clean)",Sound-treated EEG lab,"Digital EEG (raw, clean, RCA), behavioral ratings","Filtering, downsampling, artifact rejection, re-referencing, spatial filtering (RCA)",CC BY 4.0,"RCA, Inter-subject correlation, Time-domain analysis","ISC, Variance explained, Behavioral-EEG correlation",Trial-aligned per condition and stimulus,ISMIR 2019 Late-Breaking/Demo
NMED-H 2.0: Naturalistic Music EEG Dataset—Hindi,"Kaneshiro, Blair, Nguyen, Duc T., Dmochowski, Jacek P., Norcia, Anthony M., and Berger, Jonathan",2019,https://purl.stanford.edu/sd922db3535,https://purl.stanford.edu/sd922db3535,This study examined how intact and manipulated temporal structure of Hindi pop music affects inter-subject EEG correlation.,Naturalistic,Complete Musical Piece,Four Various Hindi pop songs – time-reversed,Various,NA,~4.5 minutes,"Temporal reversal, Backward structure, Neural dissimilarity","Each participant heard one of four songs under four temporal conditions (intact, shuffled, reversed, scrambled); listened twice per stimulus and rated Pleasantness, Musicality, Order, and Interest",12,"Adults with normal hearing; 50% female, right-handed",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system + reference",ISC and behavioral alignment lowest in reversed condition; backward temporal structure led to neural dissimilarity.,"1000 Hz (raw), 125 Hz (clean)",Sound-treated EEG lab,"Digital EEG (raw, clean, RCA), behavioral ratings","Filtering, downsampling, artifact rejection, re-referencing, spatial filtering (RCA)",CC BY 4.0,"RCA, Inter-subject correlation, Time-domain analysis","ISC, Variance explained, Behavioral-EEG correlation",Trial-aligned per condition and stimulus,ISMIR 2019 Late-Breaking/Demo
NMED-H 2.0: Naturalistic Music EEG Dataset—Hindi,"Kaneshiro, Blair, Nguyen, Duc T., Dmochowski, Jacek P., Norcia, Anthony M., and Berger, Jonathan",2019,https://purl.stanford.edu/sd922db3535,https://purl.stanford.edu/sd922db3535,This study examined how intact and manipulated temporal structure of Hindi pop music affects inter-subject EEG correlation.,Naturalistic,Complete Musical Piece,Four Various Hindi pop songs – phase-scrambled,Various,NA,~4.5 minutes,"Phase incoherence, Rhythm loss, Cortical noise sensitivity","Each participant heard one of four songs under four temporal conditions (intact, shuffled, reversed, scrambled); listened twice per stimulus and rated Pleasantness, Musicality, Order, and Interest",12,"Adults with normal hearing; 50% female, right-handed",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system + reference",Phase-scrambled condition yielded lowest ISC; loss of rhythm coherence disrupted EEG alignment.,"1000 Hz (raw), 125 Hz (clean)",Sound-treated EEG lab,"Digital EEG (raw, clean, RCA), behavioral ratings","Filtering, downsampling, artifact rejection, re-referencing, spatial filtering (RCA)",CC BY 4.0,"RCA, Inter-subject correlation, Time-domain analysis","ISC, Variance explained, Behavioral-EEG correlation",Trial-aligned per condition and stimulus,ISMIR 2019 Late-Breaking/Demo
MAD-EEG: an EEG dataset for decoding auditory attention to a target instrument in polyphonic music,"Giorgia Cantisani, Gabriel Trégoat, Slim Essid, Gaël Richard",2019,https://hal.telecom-paris.fr/hal-02291882v1,https://zenodo.org/records/4537751#.YS5MOI4zYuU,"This is an open-access EEG dataset designed to decode auditory attention to a target instrument within polyphonic music, using realistic stimuli and single-trial recordings from subjects instructed to selectively attend to specific instruments in duets and trios.",Controlled,Complete Musical Piece,"Pop music duets (Voice, Guitar, Bass, Drums)",Multiple commercial pop,NA,6 seconds (looped 4x),"Attention, Spectrogram correlation, Instrument tracking, Spatial rendering",Attend to one target instrument in 2-instrument pop mixes,8,"Adults, 7 male 1 female, ages 23–54, mostly right-handed",Minimal Training (<5 years),B-Alert X24 (Advanced Brain Monitoring),"20 channels, 10–20 system",Decoding succeeded in pop duets using simple linear model; performance linked to spatial cues and instrument familiarity. Significant correlation with attended pop instrument (r > unattended); EEG decoding accuracy >78% in duets.,256 Hz,"Audio-visual lab, stereo speaker setup at ±45°",Digital EEG traces + synchronized stimuli,"Visual inspection, ICA, 50 Hz notch, time-aligned audio triggers","© Speech, Music and Mind Workshop 2019","Stimulus reconstruction via linear regression, Spectrogram alignment","Pearson correlation, Wilcoxon signed-rank, Randomization test",Stimulus onset via serial port timestamp,"Speech, Music and Mind Workshop at Interspeech 2019"
MAD-EEG: an EEG dataset for decoding auditory attention to a target instrument in polyphonic music,"Giorgia Cantisani, Gabriel Trégoat, Slim Essid, Gaël Richard",2019,https://hal.telecom-paris.fr/hal-02291882v1,https://zenodo.org/records/4537751#.YS5MOI4zYuU,"This is an open-access EEG dataset designed to decode auditory attention to a target instrument within polyphonic music, using realistic stimuli and single-trial recordings from subjects instructed to selectively attend to specific instruments in duets and trios.",Controlled,Complete Musical Piece,"Pop music trios (Voice, Guitar, Bass, Drums)",Multiple commercial pop,NA,6 seconds (looped 4x),"Attention, Spectrogram correlation, Instrument tracking, Spatial rendering",Attend to one target instrument in 3-instrument pop mixes,8,"Adults, 7 male 1 female, ages 23–54, mostly right-handed",Minimal Training (<5 years),B-Alert X24 (Advanced Brain Monitoring),"20 channels, 10–20 system",Instrument identification from EEG more difficult with 3 overlapping sources; attention decoding remains above chance,256 Hz,"Audio-visual lab, stereo speaker setup at ±45°",Digital EEG traces + synchronized stimuli,"Visual inspection, ICA, 50 Hz notch, time-aligned audio triggers","© Speech, Music and Mind Workshop 2019","Stimulus reconstruction via linear regression, Spectrogram alignment","Pearson correlation, Wilcoxon signed-rank, Randomization test",Stimulus onset via serial port timestamp,"Speech, Music and Mind Workshop at Interspeech 2019"
MAD-EEG: an EEG dataset for decoding auditory attention to a target instrument in polyphonic music,"Giorgia Cantisani, Gabriel Trégoat, Slim Essid, Gaël Richard",2019,https://hal.telecom-paris.fr/hal-02291882v1,https://zenodo.org/records/4537751#.YS5MOI4zYuU,"This is an open-access EEG dataset designed to decode auditory attention to a target instrument within polyphonic music, using realistic stimuli and single-trial recordings from subjects instructed to selectively attend to specific instruments in duets and trios.",Controlled,Complete Musical Piece,"Classical music duets (Flute, Oboe, French Horn, Bassoon, Cello)",Multiple classical excerpts,NA,6 seconds (looped 4x),"Attention, Spectrogram correlation, Instrument tracking, Spatial rendering",Attend to one target instrument in 2-instrument classical mixes,8,"Adults, 7 male 1 female, ages 23–54, mostly right-handed",Minimal Training (<5 years),B-Alert X24 (Advanced Brain Monitoring),"20 channels, 10–20 system",EEG decoding correlated with musical line complexity and instrument prominence in classical duets,256 Hz,"Audio-visual lab, stereo speaker setup at ±45°",Digital EEG traces + synchronized stimuli,"Visual inspection, ICA, 50 Hz notch, time-aligned audio triggers","© Speech, Music and Mind Workshop 2019","Stimulus reconstruction via linear regression, Spectrogram alignment","Pearson correlation, Wilcoxon signed-rank, Randomization test",Stimulus onset via serial port timestamp,"Speech, Music and Mind Workshop at Interspeech 2019"
MAD-EEG: an EEG dataset for decoding auditory attention to a target instrument in polyphonic music,"Giorgia Cantisani, Gabriel Trégoat, Slim Essid, Gaël Richard",2019,https://hal.telecom-paris.fr/hal-02291882v1,https://zenodo.org/records/4537751#.YS5MOI4zYuU,"This is an open-access EEG dataset designed to decode auditory attention to a target instrument within polyphonic music, using realistic stimuli and single-trial recordings from subjects instructed to selectively attend to specific instruments in duets and trios.",Controlled,Complete Musical Piece,"Classical music trios (Flute, Oboe, French Horn, Bassoon, Cello)",Multiple classical excerpts,NA,6 seconds (looped 4x),"Attention, Spectrogram correlation, Instrument tracking, Spatial rendering",Attend to one target instrument in 3-instrument classical mixes,8,"Adults, 7 male 1 female, ages 23–54, mostly right-handed",Minimal Training (<5 years),B-Alert X24 (Advanced Brain Monitoring),"20 channels, 10–20 system","Findings support feasibility of attention tracking in realistic classical trios, but accuracy drops with complexity",256 Hz,"Audio-visual lab, stereo speaker setup at ±45°",Digital EEG traces + synchronized stimuli,"Visual inspection, ICA, 50 Hz notch, time-aligned audio triggers","© Speech, Music and Mind Workshop 2019","Stimulus reconstruction via linear regression, Spectrogram alignment","Pearson correlation, Wilcoxon signed-rank, Randomization test",Stimulus onset via serial port timestamp,"Speech, Music and Mind Workshop at Interspeech 2019"
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,La Gazza Ladra: Overture,Gioachino Rossini,La Gazza Ladra: Overture,1 minute,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed: 10 participants with >1 year musical training,"BrainAmp DC (Exp1), BioSemi ActiveTwo (Exp2/3)",60/64 channels,ISC decreased most sharply with repetition for familiar music (Rossini excerpt).,"1000 Hz (Exp1), 512 Hz (Exp2/3)",Sound-treated laboratory room,Digital EEG traces (filtered and downsampled),"Robust PCA, Filtering, EOG regression, Artifact rejection",Creative Commons Attribution 4.0,"Correlated Component Analysis (ISC), Spectral Flux Computation","Repeated-Measures ANOVA, t-tests, Permutation tests",Onset and Offset Triggers with StimTracker,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"A Faust Symphony, 3. Mephistopheles",Franz Liszt,"A Faust Symphony, Mephistopheles",1 minute 33 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,"BrainAmp DC (Exp1), BioSemi ActiveTwo (Exp2/3)",60/64 channels,ISC decreased across repetitions for familiar Liszt excerpt.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Robust PCA, Filtering, Artifact rejection",Creative Commons Attribution 4.0,Correlated Component Analysis (ISC),"Repeated-Measures ANOVA, t-tests, Permutation",Onset and Offset triggers,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"String Quartet No. 3 in D Major, Op. 44 No. 1, I. Molto allegro vivace",Felix Mendelssohn,"String Quartet No. 3 in D Major, Op. 44 No. 1, I.",1 minute 46 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC decreased over repeats for familiar Mendelssohn excerpt.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Robust PCA, Artifact Rejection, Filtering",Creative Commons Attribution 4.0,ISC via CCA,"Repeated-Measures ANOVA, t-tests, Permutation",Time-lock to music onset,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Five Orchestral Pieces, Op. 16 I. Vorgefühle",Arnold Schoenberg,Five Orchestral Pieces Op. 16 I. Vorgefühle,1 minute,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC sustained across repeats for unfamiliar Schoenberg excerpt.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Robust PCA, Artifact Removal",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Time-locked triggers,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Contrapunctus IX from The Art of Fugue, BWV 1080",Johann Sebastian Bach,Contrapunctus IX from The Art of Fugue,1 minute 5 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC remained high across repetitions for Bach fugue.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Robust PCA, Artifact rejection",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Time-locked to music onset,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,Adagio from Concerto for Oboe and Strings in D Minor,Alessandro Marcello,Adagio from Oboe Concerto in D Minor,1 minute,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC decreased moderately over repetitions for familiar Marcello excerpt.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Robust PCA, Filtering, Artifact correction",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Event markers music onset,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Toccata in D Minor, BWV 565",Johann Sebastian Bach,Toccata in D Minor BWV 565,59 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC strong initially but declined slightly across repeats for Bach Toccata.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact correction, Robust PCA",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Stimulus onset aligned,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,Sinfonia from Cantata No. 29,Johann Sebastian Bach,Sinfonia from Cantata No. 29,1 minute,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC sustained across repeats for Sinfonia excerpt.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Filtering, Artifact rejection, ICA",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Time markers per repetition,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Violin Partita No. 2 in D Minor, BWV 1004: Chaconne",Johann Sebastian Bach,Chaconne from Partita No. 2,1 minute 15 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,"ISC steady across repeats, high synchrony for Bach Chaconne.",1000/512 Hz,Sound-treated lab room,Digital EEG,"Filtering, EOG regression, Artifact removal",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Stimulus onset triggers,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Excerpt from ""Ich habe genug,"" BWV 82",Johann Sebastian Bach,Ich habe genug BWV 82 excerpt,1 minute 1 second,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC started high and slightly declined across repeats.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact rejection, Robust PCA",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Time-locked to music onset,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,Minuet from Anna Magdalena Notebook,Johann Sebastian Bach,Minuet from Anna Magdalena Notebook,55 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC moderately decreased over repetitions for Minuet.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact removal, Filtering",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Stimulus onset per repeat,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Excerpt from Brandenburg Concerto No. 3, BWV 1048",Johann Sebastian Bach,Brandenburg Concerto No. 3 excerpt,1 minute 3 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC sustained at relatively high levels across repeats.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Robust PCA, Filtering",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Music excerpt onset markers,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Excerpt from Cello Suite No. 1 in G Major, BWV 1007",Johann Sebastian Bach,Cello Suite No. 1 G Major excerpt,1 minute 7 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC gradually decreased with familiarity over repetitions.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact correction, Filtering",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Beat-locked to stimulus onset,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,Fugue from Well-Tempered Clavier Book 1 in C Major,Johann Sebastian Bach,Fugue in C Major WTC Book 1,1 minute 8 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,High ISC initially; declined slightly by last repetition.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact rejection, Robust PCA",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Stimulus-aligned trigger markers,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Excerpt from Brandenburg Concerto No. 5, BWV 1050",Johann Sebastian Bach,Brandenburg Concerto No. 5 excerpt,1 minute 7 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC initially high and stable; slight decline by final repeat.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact rejection, Filtering",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Music excerpt onset aligned,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Excerpt from Well-Tempered Clavier Book 2 in C Minor, BWV 871",Johann Sebastian Bach,Fugue in C Minor WTC Book 2,1 minute 1 second,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC consistently high across all presentations.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact removal, PCA",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Stimulus markers per excerpt,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Piano Sonata No. 11, K. 331 (1st Movement excerpt)",Wolfgang Amadeus Mozart,Piano Sonata No. 11 K. 331 excerpt,1 minute 2 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,"ISC moderate, slightly decreasing with repeats.",1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact cleaning, Filtering",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Event-locked to music start,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Excerpt from Mass in B Minor, BWV 232 (Gloria)",Johann Sebastian Bach,Mass in B Minor Gloria excerpt,1 minute 1 second,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC stable and strong even across multiple repetitions.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Robust PCA, Filtering",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Onset-aligned,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Excerpt from Harpsichord Concerto No. 5, BWV 1056",Johann Sebastian Bach,Harpsichord Concerto No. 5 excerpt,1 minute 5 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC declined slightly but remained robust by last repeat.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact rejection, Filtering",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Stimulus-aligned,Scientific Reports 9:3576
"Music synchronizes brainwaves across listeners with strong effects of repetition, familiarity, and training","Jens Madsen, Elizabeth Hellmuth Margulis, Rhimmon Simchy-Gross, Lucas C. Parra",2019,https://doi.org/10.1038/s41598-019-40254-w,Available upon request,"This study measured inter-subject correlation (ISC) of EEG responses to repeated listening of classical instrumental music, investigating effects of repetition, familiarity, and musical training on neural synchrony.",Controlled,Musical Excerpt,"Piano Sonata in F Major, K. 280 (1st Movement excerpt)",Wolfgang Amadeus Mozart,Piano Sonata in F Major K. 280 excerpt,1 minute 0 seconds,"Familiarity, ISC slope, Repetition effects",EEG-monitored passive listening; repeated exposure; attention/distract manipulation,20,"University students, ages 18–34, mixed gender",Mixed,BrainAmp DC / BioSemi ActiveTwo,60/64 channels,ISC dropped more quickly across repeats than other excerpts.,1000/512 Hz,Sound-treated lab room,Digital EEG,"Artifact removal, Filtering",Creative Commons Attribution 4.0,Correlated Component Analysis,Repeated-Measures ANOVA,Music onset markers,Scientific Reports 9:3576
Cortical encoding of melodic expectations in human temporal cortex,"Di Liberto, Pelofi, Bianco, Patel, Mehta, Herrero, de Cheveigné, Shamma, Mesgarani",2020,https://doi.org/10.5061/dryad.g1jwstqmh,https://doi.org/10.5061/dryad.g1jwstqmh,Examines how melodic expectations are encoded in low-rate cortical EEG responses using monophonic instrumental music. Naturalistic listening with computational modeling of melodic surprise and entropy.,Controlled,Musical Excerpt,10 monophonic Bach excerpts synthesized as piano MIDI from violin and flute partitas,J.S. Bach,"BWV 1001, 1002, 1004, 1006; BWV 1013",~150 seconds per excerpt,"Melodic surprise, melodic entropy, envelope tracking",Passive listening; subjects fixated visually while listening to 30 trials (10 excerpts × 3 repetitions),20,"Healthy adults (10 musicians with formal training, 10 non-musicians), ages 23–42",Mixed groups,BioSemi ActiveTwo,64 channels,EEG responses reflected encoding of melodic expectations; musicians had stronger prediction correlations; TRF amplitudes were modulated by melodic surprise,512 Hz,Sound-attenuated room,Analog EEG traces,1–8 Hz Butterworth filter; downsampled to 64 Hz; bad channels interpolated; mastoid average referencing,Open Access (Dryad),mTRF; ERP analysis; linear regression,Permutation tests; ANOVA; FDR correction,Note onsets aligned; trials repeated 3×,eLife
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 1 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 2 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 3 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 4 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 5 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 6 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 7 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 8 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 9 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Musical Expertise Enhances the Cortical Tracking of the Acoustic Envelope During Naturalistic Music Listening,"Di Liberto, Pelofi, Shamma, de Cheveigné",2020,https://doi.org/10.1250/ast.41.361,Not publicly provided,"This study investigated how musical expertise affects cortical tracking of the acoustic envelope during continuous music listening, using EEG to measure envelope tracking fidelity across musicians and non-musicians.",Controlled,Musical Excerpt,Monophonic Excerpt 10 (MIDI violin/flute rendered with piano timbre),J.S. Bach,NA,~2 minutes,"Acoustic envelope tracking (P1, N1, P2 TRF components)",EEG-monitored passive listening; participants fixated visually during auditory stimulus,14,"Healthy adults (ages 24–37), 7 musicians and 7 non-musicians",Mixed Groups,BioSemi ActiveTwo,64 channels,Musicians exhibited significantly stronger cortical tracking (higher TRF amplitudes and reconstruction accuracies) compared to non-musicians; no effect of familiarity ratings between groups,512 Hz,Sound-attenuated room,Digital EEG signals,0.5–45 Hz Butterworth filter; downsampled to 128 Hz; bad channels interpolated; average mastoid referencing; artifact rejection applied,© 2020 Acoustical Society of Japan,Multivariate Temporal Response Function (mTRF); Forward and Backward Models; Multiway Canonical Correlation Analysis (MCCA),Paired t-tests; permutation tests; effect size analysis; correlation analysis,Trial timing (piece presented 3×),Acoustical Science and Technology 41(1):361–364
Natural music evokes correlated EEG responses reflecting temporal structure and beat,"Kaneshiro, Blair, Nguyen, Duc T., Norcia, Anthony M., Dmochowski, Jacek P., Berger, Jonathan",2020,https://doi.org/10.1016/j.neuroimage.2020.116559,https://purl.stanford.edu/sd922db3535,This study tested EEG synchronization and coherence using intact and manipulated Hindi pop songs.,Controlled,Complete Musical Piece,"Hindi pop song with intact and manipulated structure (measure-shuffled, reversed, scrambled)",Salim–Sulaiman,Ainvayi Ainvayi (Band Baaja Baaraat),~4.5 minutes,"Temporal structure, Beat, ISC, SRC, CPSD phase, Coherence","Attentive passive listening; participants rated pleasantness, musicality, order, and interest after each condition",48,"Right-handed adults, ages 18–34, normal hearing, mixed gender, 32 had formal musical training, mean = 7.57 years","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system",All songs showed higher ISC and coherence in intact condition; manipulation reduced neural alignment.,1000 Hz,Shielded booth with trigger-synced audio,"Digital EEG (.mat), Behavioral ratings (.csv)","Bandpass filtering (0.3–50 Hz), downsampling (125 Hz), ICA, baseline correction, average referencing",CC BY 4.0,"ISC, SRC, RCA, CPSD phase, Coherence","Repeated-measures ANOVA, Linear mixed models, Permutation testing, Circular ANOVA",Square-wave pulses via audio output to EEG amplifier,NeuroImage 214 (2020): 116559
Natural music evokes correlated EEG responses reflecting temporal structure and beat,"Kaneshiro, Blair, Nguyen, Duc T., Norcia, Anthony M., Dmochowski, Jacek P., Berger, Jonathan",2020,https://doi.org/10.1016/j.neuroimage.2020.116559,https://purl.stanford.edu/sd922db3535,This study tested EEG synchronization and coherence using intact and manipulated Hindi pop songs.,Controlled,Complete Musical Piece,"Hindi pop song with intact and manipulated structure (measure-shuffled, reversed, scrambled)",Pritam Chakraborty,Daaru Desi (Cocktail),~4.5 minutes,"Temporal structure, Beat, ISC, SRC, CPSD phase, Coherence","Attentive passive listening; participants rated pleasantness, musicality, order, and interest after each condition",48,"Right-handed adults, ages 18–34, normal hearing, mixed gender","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system",CPSD and SRC measures confirmed stronger alignment in intact versions compared to scrambled forms.,1000 Hz,Shielded booth with trigger-synced audio,"Digital EEG (.mat), Behavioral ratings (.csv)","Bandpass filtering (0.3–50 Hz), downsampling (125 Hz), ICA, baseline correction, average referencing",CC BY 4.0,"ISC, SRC, RCA, CPSD phase, Coherence","Repeated-measures ANOVA, Linear mixed models, Permutation testing, Circular ANOVA",Square-wave pulses via audio output to EEG amplifier,NeuroImage 214 (2020): 116559
Natural music evokes correlated EEG responses reflecting temporal structure and beat,"Kaneshiro, Blair, Nguyen, Duc T., Norcia, Anthony M., Dmochowski, Jacek P., Berger, Jonathan",2020,https://doi.org/10.1016/j.neuroimage.2020.116559,https://purl.stanford.edu/sd922db3535,This study tested EEG synchronization and coherence using intact and manipulated Hindi pop songs.,Controlled,Complete Musical Piece,"Hindi pop song with intact and manipulated structure (measure-shuffled, reversed, scrambled)",Salim–Sulaiman,Haule Haule (Rab Ne Bana Di Jodi),~4.5 minutes,"Temporal structure, Beat, ISC, SRC, CPSD phase, Coherence","Attentive passive listening; participants rated pleasantness, musicality, order, and interest after each condition",48,"Right-handed adults, ages 18–34, normal hearing, mixed gender","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system",Attentive listening and formal training improved EEG correlation; reversed structure disrupted beat tracking.,1000 Hz,Shielded booth with trigger-synced audio,"Digital EEG (.mat), Behavioral ratings (.csv)","Bandpass filtering (0.3–50 Hz), downsampling (125 Hz), ICA, baseline correction, average referencing",CC BY 4.0,"ISC, SRC, RCA, CPSD phase, Coherence","Repeated-measures ANOVA, Linear mixed models, Permutation testing, Circular ANOVA",Square-wave pulses via audio output to EEG amplifier,NeuroImage 214 (2020): 116559
Natural music evokes correlated EEG responses reflecting temporal structure and beat,"Kaneshiro, Blair, Nguyen, Duc T., Norcia, Anthony M., Dmochowski, Jacek P., Berger, Jonathan",2020,https://doi.org/10.1016/j.neuroimage.2020.116559,https://purl.stanford.edu/sd922db3535,This study tested EEG synchronization and coherence using intact and manipulated Hindi pop songs.,Controlled,Complete Musical Piece,"Hindi pop song with intact and manipulated structure (measure-shuffled, reversed, scrambled)",Pritam Chakraborty,Malang (Dhoom 3),~4.5 minutes,"Temporal structure, Beat, ISC, SRC, CPSD phase, Coherence","Attentive passive listening; participants rated pleasantness, musicality, order, and interest after each condition",48,"Right-handed adults, ages 18–34, normal hearing, mixed gender","Mixed Groups, Moderate Training (5-10 years)",Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system",Malang stimulus confirmed drop in neural coherence during temporal disruption; circular ANOVA supported timing sensitivity.,1000 Hz,Shielded booth with trigger-synced audio,"Digital EEG (.mat), Behavioral ratings (.csv)","Bandpass filtering (0.3–50 Hz), downsampling (125 Hz), ICA, baseline correction, average referencing",CC BY 4.0,"ISC, SRC, RCA, CPSD phase, Coherence","Repeated-measures ANOVA, Linear mixed models, Permutation testing, Circular ANOVA",Square-wave pulses via audio output to EEG amplifier,NeuroImage 214 (2020): 116559
Neural and physiological data from participants listening to affective music,"Ian Daly, Nicoletta Nicolaou, Duncan Williams, Faustina Hwang, Alexis Kirke, Eduardo Miranda, Slawomir J. Nasuto",2020,https://doi.org/10.1038/s41597-020-0507-6,https://doi.org/10.18112/openneuro.ds002721.v1.0.1,"Participants passively listened to 12-second film music clips labeled for emotional content. After each excerpt, they rated their emotional response along eight dimensions using Likert scales.",Controlled,Musical Excerpt,Short film music clips labeled for emotion,Multiple film composers,NA,12 seconds,"Pleasantness, Energy, Tension, Fear, Happiness, Sadness, Anger, Tenderness",Passive listening with self-report on 8 emotion axes using Likert scale,31,"Ages 18–66, 13 male 18 female, healthy adults",Not Reported,BrainProducts BrainAmp,"19 channels, 10/20 system","EEG analysis revealed frontal asymmetry correlates associated with distinct self-reported emotions (e.g., sadness, tension, happiness). Trial-averaged data aligned with expected patterns of affective brain responses.",1000 Hz,Quiet lab with fixation cross,Digital EEG traces,"ICA, visual inspection, removal of noisy trials ±100μV",© 2020 The Authors (CC BY 4.0),"Frontal asymmetry, Emotion-tagged EEG analysis","t-tests, within-subject comparisons",Time-locked to music onset,Nature Scientific Data 7:177 (2020)
Neural and physiological data from participants listening to affective music,"Ian Daly, Nicoletta Nicolaou, Duncan Williams, Faustina Hwang, Alexis Kirke, Eduardo Miranda, Slawomir J. Nasuto",2020,https://doi.org/10.1038/s41597-020-0507-6,https://doi.org/10.18112/openneuro.ds002722.v1.0.1,"Participants passively listened to 12-second film music clips labeled for emotional content. After each excerpt, they rated their emotional response along eight dimensions using Likert scales.",Controlled,Computer-Generated Music,"Music generated to induce affective trajectories (e.g., calm → excited)",Generated via Max/MSP,NA,21 seconds,"Valence, Arousal, Affective trajectories",Participants reported affective states during listening via FEELTRACE,19,"Ages 19–30, 9 male 10 female",Not Reported,BrainProducts BrainAmp,"19 channels, 10/20 system","Real-time affect reporting revealed predictable EEG and physiological patterns (e.g., GSR, ECG) aligned with target emotion trajectories. Frontal asymmetry tracked intended affective changes during listening.",1000 Hz,Lab with onscreen affect-tracking (FEELTRACE),"Digital EEG, ECG, GSR traces","Automated rejection, threshold ±100μV, visual spot-checking",© 2020 The Authors (CC BY 4.0),"Frontal asymmetry, Affective state tracking, GSR-based feedback","Multivariate analysis, regressions, t-tests","Trial onset, music onset, FEELTRACE input",Nature Scientific Data 7:177 (2020)
Neural and physiological data from participants listening to affective music,"Ian Daly, Nicoletta Nicolaou, Duncan Williams, Faustina Hwang, Alexis Kirke, Eduardo Miranda, Slawomir J. Nasuto",2020,https://doi.org/10.1038/s41597-020-0507-6,https://doi.org/10.18112/openneuro.ds002724.v1.0.1,"Participants passively listened to 12-second film music clips labeled for emotional content. After each excerpt, they rated their emotional response along eight dimensions using Likert scales.",Controlled,Computer-Generated Music,Music clips targeting affective transitions (valence/arousal shifts),Generated via Max/MSP,NA,40 seconds,"Valence, Arousal trajectories over time",Participants reported felt emotion in real-time with FEELTRACE,10,"Ages 19–30, 3 male 7 female",Not Reported,BrainProducts BrainAmp,"19 channels, 10/20 system",Temporal EEG dynamics and real-time FEELTRACE data demonstrated encoding of shifting valence/arousal states. Feedback loops enabled modeling of personalized affect trajectories over time.,1000 Hz,Controlled lab with feedback display,"Digital EEG, ECG, GSR traces","Automated rejection, threshold ±100μV, visual spot-checking",© 2020 The Authors (CC BY 4.0),"Temporal affect encoding, EEG trajectories, Feedback adaptation","Repeated measures, within-participant modeling","Trial onset, FEELTRACE reporting windows",Nature Scientific Data 7:177 (2020)
Neural and physiological data from participants listening to affective music,"Ian Daly, Nicoletta Nicolaou, Duncan Williams, Faustina Hwang, Alexis Kirke, Eduardo Miranda, Slawomir J. Nasuto",2020,https://doi.org/10.1038/s41597-020-0507-6,https://doi.org/10.18112/openneuro.ds002723.v1.1.0,"Participants passively listened to 12-second film music clips labeled for emotional content. After each excerpt, they rated their emotional response along eight dimensions using Likert scales.",Controlled,Computer-Generated Music,"BCMI-generated affective music (online, personalized)",Generated via Max/MSP,NA,60 seconds,"Real-time affect control, Music feedback loop",BCMI attempts to change affective state in real time,8,"Ages 19–30, 2 male 6 female",Not Reported,BrainProducts BrainAmp,"19 channels, 10/20 system","EEG and physiological responses showed that online-generated music could dynamically influence user affect. Neural markers tracked effective affect modulation attempts, confirming feasibility of closed-loop BCMI.",1000 Hz,Real-time feedback with auditory/music and visual cues,"Digital EEG, ECG, GSR traces","Post-hoc thresholding ±100μV, visual inspection",© 2020 The Authors (CC BY 4.0),"Affective trajectory tracking, online decoding, EEG-GSR correlation","Mixed effects modeling, feedback analysis","Music onset, system action marker",Nature Scientific Data 7:177 (2020)
Neural and physiological data from participants listening to affective music,"Ian Daly, Nicoletta Nicolaou, Duncan Williams, Faustina Hwang, Alexis Kirke, Eduardo Miranda, Slawomir J. Nasuto",2020,https://doi.org/10.1038/s41597-020-0507-6,https://doi.org/10.18112/openneuro.ds002720.v1.0.1,"Participants passively listened to 12-second film music clips labeled for emotional content. After each excerpt, they rated their emotional response along eight dimensions using Likert scales.",Controlled,Computer-Generated Music,Max/MSP Tempo-adjustable music generated for motor-imagery control,Generated via Max/MSP,NA,12 seconds (per trial),"Tempo, Motor-imagery modulation, Feedback",Users control tempo through upper limb motor imagery,18,"Ages 19–28, 14 male 4 female",Not Reported,BrainProducts BrainAmp,"19 channels, 10/20 system","Event-related desynchronization/synchronization (ERD/ERS) in EEG correlated with successful tempo modulation. Changes in tempo entrained sensorimotor EEG patterns, especially in motor-related electrodes.",1000 Hz,Lab with onscreen tempo/ball feedback,Digital EEG traces,"Visual rejection, artifact detection on F3, T3, C3, Cz, P3",© 2020 The Authors (CC BY 4.0),Event-related desynchronization/synchronization (ERD/ERS),"t-tests, time-frequency analysis","Trial start, Feedback onset",Nature Scientific Data 7:177 (2020)
Neural and physiological data from participants listening to affective music,"Ian Daly, Nicoletta Nicolaou, Duncan Williams, Faustina Hwang, Alexis Kirke, Eduardo Miranda, Slawomir J. Nasuto",2020,https://doi.org/10.1038/s41597-020-0507-6,https://doi.org/10.18112/openneuro.ds002725.v1.0.1,"Participants passively listened to 12-second film music clips labeled for emotional content. After each excerpt, they rated their emotional response along eight dimensions using Likert scales.",Controlled,Computer-Generated Music,Same musical stimuli as BCMI study recorded during simultaneous EEG-fMRI,Generated via Max/MSP,NA,40 seconds,"Affective state, EEG-fMRI cross-modal coherence",Participants listened while undergoing simultaneous EEG-fMRI recording,1,"Right-handed male, age ~26",Not Reported,EEG: BrainAmp MR Plus (MR-compatible) + fMRI (Siemens),"19 channel, 10/20 system + fMRI voxels",Preliminary analysis confirmed alignment between EEG source components and fMRI signals during music listening. Artifact-corrected EEG and BOLD data suggested cross-modal coherence during emotion tracking.,5000 Hz ,fMRI scanner with MR-compatible EEG cap,"Digital EEG (EEGlab format), fMRI (NIfTI)","Gradient and pulse artifact correction, ICA, slice-time corrected fMRI",© 2020 The Authors (CC BY 4.0),"EEG-fMRI correlation, ICA source separation, Artifact modeling","Qualitative pilot analysis, artifact noise assessment","fMRI scan onset, EEG sync pulses, music onset",Nature Scientific Data 7:177 (2020)
NMED-M Naturalistic Music EEG Dataset - Minimalism | Inter-Subject Correlation during New Music Listening: A Study of Electrophysiological and Behavioral Responses to Steve Reich’s Piano Phase,"Dauer, Tysen, Nguyen, Duc T., Gang, Nick, Dmochowski, Jacek P., Berger, Jonathan, Kaneshiro, Blair",2021,https://doi.org/10.1101/2021.04.27.441708,https://purl.stanford.edu/kt396gb0630,Study examined EEG and behavioral synchronization to minimalist music using different versions of Piano Phase.,Naturalistic,Complete Musical Piece,Original 1987 recording of *Piano Phase* by Nurit Tilles and Edmund Neimann,Steve Reich,Piano Phase (Original),6 minutes,"Minimalist structure, Temporal phasing, Inter-subject correlation",Participants passively listened to full piece and later provided behavioral ratings and continuous engagement tracking,30,"Adults with normal hearing, mixed gender",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system","Original version showed strong ISC and CB alignment, confirming neural coherence in minimalist structure.","1000 Hz (raw), 125 Hz (cleaned)",Acoustically treated EEG lab,"Digital EEG (.mat), Behavioral ratings (.csv), Continuous behavior (.mat)","High-pass filter, downsampling, ICA, interpolation, re-referencing, trial averaging",CC BY 4.0,"ISC, RCA, EEG–CB alignment, Engagement analysis","Repeated-measures correlation, ISC comparisons",Stimulus-aligned EEG and CB markers,bioRxiv 2021.04.27.441708
NMED-M Naturalistic Music EEG Dataset - Minimalism | Inter-Subject Correlation during New Music Listening: A Study of Electrophysiological and Behavioral Responses to Steve Reich’s Piano Phase,"Dauer, Tysen, Nguyen, Duc T., Gang, Nick, Dmochowski, Jacek P., Berger, Jonathan, Kaneshiro, Blair",2021,https://doi.org/10.1101/2021.04.27.441708,https://purl.stanford.edu/kt396gb0630,Study examined EEG and behavioral synchronization to minimalist music using different versions of Piano Phase.,Naturalistic,Complete Musical Piece,Matt Winn’s *Phased & Konfused Mix* of *Piano Phase*,"Steve Reich, Matt Winn",Piano Phase (Remix),5 minutes,"Remix structure, Beat-based layering, Listener engagement",Participants passively listened to full piece and later provided behavioral ratings and continuous engagement tracking,30,"Adults with normal hearing, mixed gender",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system",Remix version induced distinct engagement patterns; beat layering increased neural synchrony.,"1000 Hz (raw), 125 Hz (cleaned)",Acoustically treated EEG lab,"Digital EEG (.mat), Behavioral ratings (.csv), Continuous behavior (.mat)","High-pass filter, downsampling, ICA, interpolation, re-referencing, trial averaging",CC BY 4.0,"ISC, RCA, EEG–CB alignment, Engagement analysis","Repeated-measures correlation, ISC comparisons",Stimulus-aligned EEG and CB markers,bioRxiv 2021.04.27.441708
NMED-M Naturalistic Music EEG Dataset - Minimalism | Inter-Subject Correlation during New Music Listening: A Study of Electrophysiological and Behavioral Responses to Steve Reich’s Piano Phase,"Dauer, Tysen, Nguyen, Duc T., Gang, Nick, Dmochowski, Jacek P., Berger, Jonathan, Kaneshiro, Blair",2021,https://doi.org/10.1101/2021.04.27.441708,https://purl.stanford.edu/kt396gb0630,Study examined EEG and behavioral synchronization to minimalist music using different versions of Piano Phase.,Naturalistic,Complete Musical Piece,Abrupt change version of *Piano Phase* with sudden transitions between sections,Steve Reich,Piano Phase (Abrupt Change),5 minutes,"Discontinuous structure, Repetition violation, Engagement shifts",Participants passively listened to full piece and later provided behavioral ratings and continuous engagement tracking,30,"Adults with normal hearing, mixed gender",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system",Abrupt change version reduced ISC; sudden transitions disrupted temporal predictability.,"1000 Hz (raw), 125 Hz (cleaned)",Acoustically treated EEG lab,"Digital EEG (.mat), Behavioral ratings (.csv), Continuous behavior (.mat)","High-pass filter, downsampling, ICA, interpolation, re-referencing, trial averaging",CC BY 4.0,"ISC, RCA, EEG–CB alignment, Engagement analysis","Repeated-measures correlation, ISC comparisons",Stimulus-aligned EEG and CB markers,bioRxiv 2021.04.27.441708
NMED-M Naturalistic Music EEG Dataset - Minimalism | Inter-Subject Correlation during New Music Listening: A Study of Electrophysiological and Behavioral Responses to Steve Reich’s Piano Phase,"Dauer, Tysen, Nguyen, Duc T., Gang, Nick, Dmochowski, Jacek P., Berger, Jonathan, Kaneshiro, Blair",2021,https://doi.org/10.1101/2021.04.27.441708,https://purl.stanford.edu/kt396gb0630,Study examined EEG and behavioral synchronization to minimalist music using different versions of Piano Phase.,Naturalistic,Complete Musical Piece,Segment shuffle version of *Piano Phase* with reordered musical sections,Steve Reich,Piano Phase (Segment Shuffle),5 minutes,"Structural unpredictability, Minimalist motif variation, Neural entrainment",Participants passively listened to full piece and later provided behavioral ratings and continuous engagement tracking,30,"Adults with normal hearing, mixed gender",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system",Segment shuffle version showed lower ISC; unpredictable structure weakened entrainment.,"1000 Hz (raw), 125 Hz (cleaned)",Acoustically treated EEG lab,"Digital EEG (.mat), Behavioral ratings (.csv), Continuous behavior (.mat)","High-pass filter, downsampling, ICA, interpolation, re-referencing, trial averaging",CC BY 4.0,"ISC, RCA, EEG–CB alignment, Engagement analysis","Repeated-measures correlation, ISC comparisons",Stimulus-aligned EEG and CB markers,bioRxiv 2021.04.27.441708
NMED-M Naturalistic Music EEG Dataset - Minimalism | Inter-Subject Correlation during New Music Listening: A Study of Electrophysiological and Behavioral Responses to Steve Reich’s Piano Phase,"Dauer, Tysen, Nguyen, Duc T., Gang, Nick, Dmochowski, Jacek P., Berger, Jonathan, Kaneshiro, Blair",2021,https://doi.org/10.1101/2021.04.27.441708,https://purl.stanford.edu/kt396gb0630,Study examined EEG and behavioral synchronization to minimalist music using different versions of Piano Phase.,Naturalistic,Complete Musical Piece,Tremolo version of *Piano Phase* with pitch held constant and only rhythm preserved,Steve Reich,Piano Phase (Tremolo),5 minutes,"Rhythmic regularity, Pitch monotony, Listener arousal",Participants passively listened to full piece and later provided behavioral ratings and continuous engagement tracking,30,"Adults with normal hearing, mixed gender",Not Reported,Electrical Geodesics GES300 (EGI),"128 channels, 10–10 system",Tremolo version decreased ISC; pitch monotony altered listener arousal and engagement.,"1000 Hz (raw), 125 Hz (cleaned)",Acoustically treated EEG lab,"Digital EEG (.mat), Behavioral ratings (.csv), Continuous behavior (.mat)","High-pass filter, downsampling, ICA, interpolation, re-referencing, trial averaging",CC BY 4.0,"ISC, RCA, EEG–CB alignment, Engagement analysis","Repeated-measures correlation, ISC comparisons",Stimulus-aligned EEG and CB markers,bioRxiv 2021.04.27.441708
The Effect of Music Listening on EEG Functional Connectivity of Brain: A Short-Duration and Long-Duration Study,"Danyal Mahmood, Humaira Nisar, Vooi Voon Yap, Chi-Yi Tsai",2022,https://doi.org/10.3390/math10030349,NA,Short-duration study comparing EEG-FC after listening to favorite vs. relaxing music,Controlled,Complete Musical Piece,Favorite music chosen by participant,Varied (participant-selected),NA,~5 minutes,"Functional connectivity, EEG frequency bands (delta, theta, alpha, beta)",Passive listening while EEG recorded; comparisons made to pre-music baseline,Not Reported,Not Reported,Not Reported,Emotiv EPOC,"14 channels, 10-20 system",Alpha and beta band connectivity increased more after favorite music than relaxing music; theta band increased more after relaxing music,128 Hz,Sound-treated room,Digital EEG traces,"Bandpass filtering (0.5–60 Hz), ICA for ocular artifact, MATLAB-based frequency decomposition",Creative Commons Attribution (CC BY),"Inter-Site Phase Clustering (ISPC), Graph theory, Connectivity matrices","ANOVA, t-test",Time-locked to start of stimulus,Mathematics 10(3):349
The Effect of Music Listening on EEG Functional Connectivity of Brain: A Short-Duration and Long-Duration Study,"Danyal Mahmood, Humaira Nisar, Vooi Voon Yap, Chi-Yi Tsai",2022,https://doi.org/10.3390/math10030349,NA,Short-duration study comparing EEG-FC after listening to favorite vs. relaxing music,Controlled,Complete Musical Piece,Relaxing music with alpha binaural beats,NA,NA,~5 minutes,"Functional connectivity, EEG frequency bands (delta, theta, alpha, beta)",Passive listening while EEG recorded; comparisons made to pre-music baseline,Not Reported,Not Reported,Not Reported,Emotiv EPOC,"14 channels, 10-20 system",Relaxing music increased theta and average connectivity more than favorite music; showed stronger relaxation-related FC changes,128 Hz,Sound-treated room,Digital EEG traces,"Bandpass filtering (0.5–60 Hz), ICA for ocular artifact, MATLAB-based frequency decomposition",Creative Commons Attribution (CC BY),"Inter-Site Phase Clustering (ISPC), Graph theory, Connectivity matrices","ANOVA, t-test",Time-locked to start of stimulus,Mathematics 10(3):349
The Effect of Music Listening on EEG Functional Connectivity of Brain: A Short-Duration and Long-Duration Study,"Danyal Mahmood, Humaira Nisar, Vooi Voon Yap, Chi-Yi Tsai",2022,https://doi.org/10.3390/math10030349,NA,Long-duration study assessing daily music listening impact on EEG-FC,Controlled,Complete Musical Piece,Relaxing music with alpha binaural beats over 2 weeks,NA,NA,30 minutes/day for 14 days,"Functional connectivity, EEG frequency bands (delta, theta, alpha, beta)","Music Listening Group listened daily; EEG at baseline, week 1, and week 2",Not Reported,Not Reported,Not Reported,Emotiv EPOC,"14 channels, 10-20 system","Increased delta, alpha, and beta connectivity over time in the Music Listening Group; Control group showed no significant changes",128 Hz,Sound-treated room,Digital EEG traces,"Bandpass filtering (0.5–60 Hz), ICA for ocular artifact, MATLAB-based frequency decomposition",Creative Commons Attribution (CC BY),"Inter-Site Phase Clustering (ISPC), Graph theory, Connectivity matrices","ANOVA, t-test",Time-locked to weekly measurement,Mathematics 10(3):349
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"1 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Gen Hoshino,Koi,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"2 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Ed Sheeran,Shape of You,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"3 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Daoko X Kenshi Yonezu,Uchiage Hanabi,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"4 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Keyakizaka46,Fukyōwaon,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"5 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Keyakizaka46,Futari Saison,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"6 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Twice,TT,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"7 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Nogizaka 46,Influencer,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"8 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Pikotaro,PPAP (Pen-Pineapple-Apple-Pen),62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"9 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Radwimps,Zenzenzense,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"10 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Keyakizaka46,Silent Majority,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"11 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Austin Mahone,Dirty Work,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"12 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Nogizaka 46,Nigemizu,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"13 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Gen Hoshino,Family Song,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"14 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Kenshi Yonezu,Peace Sign,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"15 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",AKB48,Negaigoto no Mochigusare,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"16 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Nogizaka 46,Itsuka Dekiru kara Kyō Dekiru,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"17 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Keyakizaka46,Kaze ni Fukarete mo,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"18 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Perfume,Tokyo Girl,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"19 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Suchmos,Stay Tune,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"20 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Sekai no Owari,Rain,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
Inter-subject correlations of EEG reflect subjective arousal and acoustic features of music,"Fuyu Ueno, Sotaro Shimada",2023,https://doi.org/10.3389/fnhum.2023.1225377,NA,This study used concurrent EEG-fMRI and EEG-only recordings to reconstruct music perception from brain activity using source-localized EEG and neural decoding models. Examines whether EEG ISC reflects population music preferences using Billboard chart songs.,Controlled,Musical Excerpt,"21 on Billboard Japan Hot 100. 62-second edited clip including chorus and surrounding sections, normalized with fade-in and fade-out",Justin Bieber,What Do You Mean?,62 seconds,"Tonality, Tempo, EEG ISC, Principal Component Analysis","EEG during passive music listening followed by self-report of preference, enjoyment, frequency of listening, and arousal",17,"Healthy Japanese adults, mean age 21.4 ± 0.69, 7 female",Mixed Groups,"g.tec (BCI Research System), 30-channel setup","30 channels, 10-20 system","Higher-ranked music had significantly higher ISC values, suggesting greater listener engagement. Principal component analysis also revealed distinct clusters differing in arousal, tonality, and tempo—linking ISC to both emotional response and musical features.",512 Hz,"Lab with headphones, visual fixation cross",Not Reported,"Bandpass 1–60 Hz, 50Hz notch filter, ICA, CorrCA",CC BY,"ISC, CorrCA, PCA, clustering, GLM","t-test, ANOVA, Tukey’s HSD",Not Reported,Frontiers in Human Neuroscience Volume 17 (2023)
NMED-E Naturalistic Music EEG Dataset - Elgar | Inter-subject correlation of electroencephalographic and behavioural responses reflects time-varying engagement with natural music,"Kaneshiro, Blair, Nguyen, Duc T., Norcia, Anthony M., Dmochowski, Jacek P., Berger, Jonathan",2024,https://doi.org/10.1111/ejn.16324,https://purl.stanford.edu/pp371jh5722,This study investigated how neural and behavioral responses align over time during listening to naturalistic classical music.,Naturalistic,Complete Musical Piece,Original 1965 performance of Elgar’s Cello Concerto in E Minor,Edward Elgar,"Cello Concerto in E Minor, Op. 85 (Movement I)",8 minutes,"Temporal structure, Engagement, Inter-subject correlation, Amplitude envelope",EEG recorded during passive listening to full piece; followed by behavioral ratings and continuous behavioral tracking in separate session,24,"Right-handed adult musicians, ages ~18–35, normal hearing, fluent English, ≥5 years formal classical training, no cello experience",Moderate Training (5-10 years),Electrical Geodesics GES 300 (EGI),"128 channels, 10–10 system",Significant ISC and EEG–CB correlation observed; time-resolved ISC revealed peaks in listener engagement.,1000 Hz,Acoustically and electrically shielded EEG booth,"Digital EEG (raw and cleaned), Behavioral ratings and continuous engagement","High-pass (.3 Hz), notch (59–61 Hz), low-pass (50 Hz), downsampling (125 Hz), ICA for artifact removal, average referencing, baseline-corrected, interpolation",CC BY 4.0,"RCA, ISC, Time-resolved ISC, EEG-CB cross-correlation","Wilcoxon signed-rank tests, Permutation testing, FDR correction",Time-locked audio triggers via audio channel pulses,European Journal of Neuroscience 59(12):3162–3183
NMED-E Naturalistic Music EEG Dataset - Elgar | Inter-subject correlation of electroencephalographic and behavioural responses reflects time-varying engagement with natural music,"Kaneshiro, Blair, Nguyen, Duc T., Norcia, Anthony M., Dmochowski, Jacek P., Berger, Jonathan",2024,https://doi.org/10.1111/ejn.16324,https://purl.stanford.edu/pp371jh5722,This study investigated how neural and behavioral responses align over time during listening to naturalistic classical music.,Naturalistic,Complete Musical Piece,Phase-scrambled version of Elgar’s concerto with amplitude envelope preserved,Edward Elgar,"Cello Concerto in E Minor, Op. 85 (Phase-Scrambled)",8 minutes,"Amplitude envelope, Temporal disorganization, Inter-subject correlation",EEG recorded during passive listening to control stimulus; followed by behavioral ratings and continuous behavioral tracking in separate session,24,"Right-handed adult musicians, ages ~18–35, normal hearing, fluent English, ≥5 years formal classical training, no cello experience",Moderate Training (5-10 years),Electrical Geodesics GES 300 (EGI),"128 channels, 10–10 system",Phase-scrambled version had lower ISC; preserved amplitude envelope supported partial alignment.,1000 Hz,Acoustically and electrically shielded EEG booth,"Digital EEG (raw and cleaned), Behavioral ratings and continuous engagement","High-pass (.3 Hz), notch (59–61 Hz), low-pass (50 Hz), downsampling (125 Hz), ICA for artifact removal, average referencing, baseline-corrected, interpolation",CC BY 4.0,"RCA, ISC, Time-resolved ISC, EEG-CB cross-correlation","Wilcoxon signed-rank tests, Permutation testing, FDR correction",Time-locked audio triggers via audio channel pulses,European Journal of Neuroscience 59(12):3162–3183
Neural encoding of musical expectations in a nonhuman primate,"Roberta Bianco, Giacomo Novembre, Francesco Contini, Eleonora De Pisapia, Piergiorgio Trevisan, Mathew Diamond, Leonardo Chelazzi",2024,https://doi.org/10.1016/j.cub.2023.12.019,https://doi.org/10.48557/U5SHX6,This EEG study assessed how two rhesus monkeys encode pitch- and timing-based surprise while listening to original and temporally shuffled Bach melodies from www.jsbach.net.,Controlled,Complete Musical Piece,10 real piano melodies composed by J.S. Bach,Johann Sebastian Bach,NA,~158.07 seconds,"Pitch-based surprise, Timing-based surprise, Entropy, ERP, mTRF",Passive listening to music while watching silent videos,2,"Male rhesus monkeys, 11 years old, 10 and 9.8 kg",No Formal Training,Biosemi Active-2 system with custom monkey EEG caps,26 channels,"ERP amplitudes were larger for unexpected (high surprise) notes in real vs. shuffled music, indicating sensitivity to structure. Timing-based expectations, but not pitch-based, enhanced prediction accuracy in monkeys.",1024 Hz,"Primate chair in controlled lab, passive viewing of silent visuals",Digital EEG traces,"Artifact rejection, ERP segmentation, Bandpass filtering, Quantization to 16th notes, Amplitude normalization",CC BY license,"ERP averaging, mTRF modeling, Pitch and timing surprise modeling","Cluster-based permutation test, Linear mixed-effects model",Time-locked to note onsets and stimulus surprise values,Current Biology 34(2):444–450
Neural encoding of musical expectations in a nonhuman primate,"Roberta Bianco, Giacomo Novembre, Francesco Contini, Eleonora De Pisapia, Piergiorgio Trevisan, Mathew Diamond, Leonardo Chelazzi",2024,https://doi.org/10.1016/j.cub.2023.12.019,https://doi.org/10.48557/U5SHX6,This EEG study assessed how two rhesus monkeys encode pitch- and timing-based surprise while listening to original and temporally shuffled Bach melodies from www.jsbach.net.,Controlled,Complete Musical Piece,4 shuffled melodies derived from real Bach melodies with pitch/timing disruption,Johann Sebastian Bach (source material),NA,~158.07 seconds,"Pitch-based surprise, Timing-based entropy, ERP, mTRF",Passive listening to randomized pitch/timing melodies while watching silent videos,2,"Male rhesus monkeys, 11 years old, 10 and 9.8 kg",No Formal Training,Biosemi Active-2 system with custom monkey EEG caps,26 channels,"No significant ERP or mTRF prediction effects emerged. Monkeys failed to track surprise in these scrambled sequences, indicating expectations are not driven purely by acoustics.",1024 Hz,"Primate chair in controlled lab, passive viewing of silent visuals",Digital EEG traces,"Artifact rejection, ERP segmentation, Bandpass filtering, Quantization to 16th notes, Amplitude normalization",CC BY license,"ERP averaging, mTRF modeling, Pitch and timing surprise modeling","Cluster-based permutation test, Linear mixed-effects model",Time-locked to note onsets and stimulus surprise values,Current Biology 34(2):444–450
Music tempo modulates emotional states as revealed through EEG insights,"Zengyao Yang, Qiruo Su, Jieren Xie, Hechong Su, Tianrun Huang, Chengcheng Han, Sicong Zhang, Kai Zhang, Guanghua Xu",2025,https://doi.org/10.1038/s41598-025-92679-1,NA,"This study explored how different tempi modulate valence, arousal, and EEG features",Controlled,Musical Excerpt,"Classical piano, 56/106/156 bpm",Wolfgang Amadeus Mozart,"Mozart: Sonata for 2 Pianos in D major, K.448/375a",~13 minutes,"Valence, Arousal, Theta, Alpha, Beta, Gamma, Delta, Power Spectrum, Dispersion Entropy, Covariance, PLV",Passive listening with post-trial valence and arousal ratings,26,"Right-handed native Chinese adults, mixed gender, ages 17–38",No Formal Training,"NeuSen.W32, Neuracle","59 channels, 10–10 system",Faster tempo increased valence and frontal Beta/Gamma power; slow tempo enhanced frontal Alpha/Theta and parieto-occipital PLV,1000 Hz,Sound-treated room,Digital EEG traces,"Artifact rejection, CAR, notch filtering, bandpass filtering (0.1–90 Hz), ICA",© 2025 Springer Nature,"Power spectrum, Dispersion entropy, Covariance, PLV","ANOVA, Tukey HSD",Onset of musical stimulus,Scientific Reports 15:8276
The power of music: impact on EEG signals,"Basma Bahgat El Sayed, Mye Ali Basheer, Marwa Safwat Shalaby, Hala Rashad El Habashy, Saly Hasan Elkholy",2025,https://doi.org/10.1007/s00426-024-02060-6,NA,"This study investigated how Egyptian folk and classical music influence cortical activation patterns and interhemispheric EEG dynamics in young adults, revealing that folk music increases frontal slow-wave power while classical music evokes EEG patterns associated with relaxed cognitive states.",Controlled,Complete Musical Piece,Egyptian folk music with vocals and traditional instrumentation,Traditional Egyptian folk,NA,3 minutes,"Power Ratio Index (PRI), Interhemispheric PRI difference, QEEG bands (delta, theta, alpha, beta)",Passive listening with eyes closed during 10-min track (1 min silence → 3 min folk → 3 min silence → 3 min classic),76,"High school students (ages 15–26, mean 16.73 ± 2.37), 72% female, majority right-handed, Only 2.6% played an instrument; most had no training",No Formal Training,EBNeuro Galileo NT (Mizar version 3.61),"NA, 10–20 system","Folk music caused regional slowing and reduced cognitive processing, especially in frontal cortex",Not reported,Quiet room using headphones,Digital EEG traces,"Visual inspection, artifact rejection, PRI computed from band ratios, Jamovi analysis",© The Author(s) 2025 under CC BY 4.0,"QEEG band ratio analysis (delta+theta / alpha+beta), Interhemispheric difference","ANOVA, Friedman test, Mann–Whitney U, Durbin–Conover pairwise, Levene’s test",Manual segmentation by audio epoch timing,Psychological Research (2025) 89:42
The power of music: impact on EEG signals,"Basma Bahgat El Sayed, Mye Ali Basheer, Marwa Safwat Shalaby, Hala Rashad El Habashy, Saly Hasan Elkholy",2025,https://doi.org/10.1007/s00426-024-02060-6,NA,"This study investigated how Egyptian folk and classical music influence cortical activation patterns and interhemispheric EEG dynamics in young adults, revealing that folk music increases frontal slow-wave power while classical music evokes EEG patterns associated with relaxed cognitive states.",Controlled,Complete Musical Piece,Egyptian instrumental classical music (no lyrics),Egyptian classical,NA,3 minutes,"Power Ratio Index (PRI), Interhemispheric PRI difference, QEEG bands (delta, theta, alpha, beta)",Passive listening with eyes closed during 10-min track (1 min silence → 3 min folk → 3 min silence → 3 min classic),76,"High school students (ages 15–26, mean 16.73 ± 2.37), 72% female, majority right-handed, Only 2.6% played an instrument; most had no training",No Formal Training,EBNeuro Galileo NT (Mizar version 3.61),"NA, 10–20 system","Classic instrumental music induced EEG patterns associated with relaxation, especially in left temporal regions",Not reported,Quiet room using headphones,Digital EEG traces,"Visual inspection, artifact rejection, PRI computed from band ratios, Jamovi analysis",© The Author(s) 2025 under CC BY 4.0,"QEEG band ratio analysis (delta+theta / alpha+beta), Interhemispheric difference","ANOVA, Friedman test, Mann–Whitney U, Durbin–Conover pairwise, Levene’s test",Manual segmentation by audio epoch timing,Psychological Research (2025) 89:42